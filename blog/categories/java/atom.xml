<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | 薛定谔的风口猪]]></title>
  <link href="https://Jaskey.github.io/blog/categories/java/atom.xml" rel="self"/>
  <link href="https://Jaskey.github.io/"/>
  <updated>2021-02-24T21:41:53+08:00</updated>
  <id>https://Jaskey.github.io/</id>
  <author>
    <name><![CDATA[Jaskey Lam]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[DUBBO] ReferenceConfig(null) Is Not DESTROYED When FINALIZE分析及解决]]></title>
    <link href="https://Jaskey.github.io/blog/2020/05/22/dubbo-refernececonfig-is-not-destroyed-when-finalize/"/>
    <updated>2020-05-22T18:14:58+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/05/22/dubbo-refernececonfig-is-not-destroyed-when-finalize</id>
    <content type="html"><![CDATA[<p>最近发现经常有类似告警：</p>

<p>​    [DUBBO] ReferenceConfig(null) is not DESTROYED when FINALIZE，dubbo version 2.6.2</p>

<p>在此记录一下分析的过程和解决方案。</p>

<h2>从日志定位源码位置</h2>

<pre><code class="java">    @SuppressWarnings("unused")
    private final Object finalizerGuardian = new Object() {
        @Override
        protected void finalize() throws Throwable {
            super.finalize();

            if (!ReferenceConfig.this.destroyed) {
                logger.warn("ReferenceConfig(" + url + ") is not DESTROYED when FINALIZE");

                /* don't destroy for now
                try {
                    ReferenceConfig.this.destroy();
                } catch (Throwable t) {
                        logger.warn("Unexpected err when destroy invoker of ReferenceConfig(" + url + ") in finalize method!", t);
                }
                */
            }
        }
    };
</code></pre>

<p>通过日志搜索源码，发现这个日志是<code>ReferenceConfig</code>类中一个<code>finalizerGuardian</code>的实例变量下复写了<code>finalize</code>而打印出来的。而从其中的源码来看，原本应该是希望做到：在发现原本的对象没有被释放资源的时候，手动回收资源。但是后面缺代码被注释了（猜测是有巨坑），就只保留了一个告警。所以实际上这个对象现在只起到了WARN日志提示的作用，并无实际作用。</p>

<p>注：复写<code>finalize</code>方法会导致一定的GC回收的性能问题，因为一个对象如果其中<code>finalize</code>被复写（哪怕只是写一个分号空实现），在垃圾回收的时候都会以单独的方法回收，简单说就是有一条独立的Finalizer线程（优先级很低）单独回收，如果对象分配频繁，会引起一定的性能问题。回到Dubbo的场景，假设在高并发的场景下不断创建ReferenceConfig对象，会影响这些对象的回收效率（并且这个过程中会产生一些<code>java.lang.ref.Finalizer</code>对象）甚至OOM，现在只是打印一个日志是一个不好的实践。对于finalize的原理和其对垃圾回收的影响可以参考<a href="https://blog.heaphero.io/2018/04/13/heaphero-user-manual-2/#ObjFin">https://blog.heaphero.io/2018/04/13/heaphero-user-manual-2/#ObjFin</a>  ，这里摘抄其中一段供参考：</p>

<blockquote><p>Objects that have finalize() method are treated differently during garbage collection process than the ones which don’t have. During garbage collection phase, objects with finalize() method aren’t immediately evicted from the memory. Instead, as the first step, those objects are added to an internal queue of java.lang.ref.Finalizer. For entire JVM, there is only one low priority JVM thread by name ‘Finalizer’ that executes finalize() method of each object in the queue. Only after the execution of finalize() method, object becomes eligible for Garbage Collection. Assume if your application is producing a lot of objects which has finalize() method and low priority “Finalizer” thread isn’t able to keep up with executing finalize() method, then significant amount unfinalized objects will start to build up in the internal queue of java.lang.ref.Finalize, which would result in significant amount of memory wastage.</p></blockquote>

<h2>问题分析</h2>

<p>从以上的源码上，这句日志打印的充分必要条件是：</p>

<p>1.ReferenceConfig被垃圾回收</p>

<p>2.垃圾回收的时候ReferenceConfig没有调用过destroy方法，即<code>!ReferenceConfig.this.destroyed</code></p>

<h2>代码始末</h2>

<p>基于以上的分析，需要知道哪里我们会创建<code>ReferenceConfig</code>对象。通常情况下，这个对象我们是不会代码显示创建的，因为正常都是Dubbo基于我们的配置（注解或者配置文件）去管理内部的对象，只有我们在泛化调用的时候，可能会手动创建。</p>

<p>Dubbo官方文档里<a href="http://dubbo.apache.org/zh-cn/docs/user/demos/generic-reference.html">http://dubbo.apache.org/zh-cn/docs/user/demos/generic-reference.html</a>  ，关于泛化调用有类似的代码，其中就会手动创建<code>ReferenceConfig</code>对象</p>

<pre><code class="java">// 引用远程服务 
// 该实例很重量，里面封装了所有与注册中心及服务提供方连接，请缓存
ReferenceConfig&lt;GenericService&gt; reference = new ReferenceConfig&lt;GenericService&gt;(); 
// 弱类型接口名
reference.setInterface("com.xxx.XxxService");  
reference.setVersion("1.0.0");
// 声明为泛化接口 
reference.setGeneric(true);  

// 用org.apache.dubbo.rpc.service.GenericService可以替代所有接口引用  
GenericService genericService = reference.get(); 

// 基本类型以及Date,List,Map等不需要转换，直接调用 
Object result = genericService.$invoke("sayHello", new String[] {"java.lang.String"}, new Object[] {"world"}); 
</code></pre>

<p>由于以上代码会存在很容易导致连接等相关资源泄露等问题，详见：<a href="http://dubbo.apache.org/zh-cn/docs/user/demos/reference-config-cache.html">http://dubbo.apache.org/zh-cn/docs/user/demos/reference-config-cache.html</a> ，所以正常的泛化调用的使用方式则变成这样：</p>

<pre><code class="java">ReferenceConfig&lt;XxxService&gt; reference = new ReferenceConfig&lt;XxxService&gt;();
reference.setInterface(XxxService.class);
reference.setVersion("1.0.0");
......
ReferenceConfigCache cache = ReferenceConfigCache.getCache();
// cache.get方法中会缓存 Reference对象，并且调用ReferenceConfig.get方法启动ReferenceConfig
XxxService xxxService = cache.get(reference);
// 注意！ Cache会持有ReferenceConfig，不要在外部再调用ReferenceConfig的destroy方法，导致Cache内的ReferenceConfig失效！
// 使用xxxService对象
xxxService.sayHello();
</code></pre>

<p>Dubbo官方对于相关建议的解释是：</p>

<blockquote><p><code>ReferenceConfig</code> 实例很重，封装了与注册中心的连接以及与提供者的连接，需要缓存。否则重复生成 <code>ReferenceConfig</code> 可能造成性能问题并且会有内存和连接泄漏。在 API 方式编程时，容易忽略此问题。</p></blockquote>

<p>但是，实际上这句话和其API的实际设计上存在一定的误解。Dubbo认为<code>ReferenceConfig</code> 实例很重，所以应该缓存这个对象，所以设计了一个<code>ReferenceConfigCache</code>类，这个类实际上可以认为就是一个Map，当第一次调用cache.get(reference)的时候，实际上会把这个<code>ReferenceConfig</code> 放到里面的Map中：</p>

<pre><code class="java">    public &lt;T&gt; T get(ReferenceConfig&lt;T&gt; referenceConfig) {
        String key = generator.generateKey(referenceConfig);

        ReferenceConfig&lt;?&gt; config = cache.get(key);
        if (config != null) {
            return (T) config.get();
        }

        cache.putIfAbsent(key, referenceConfig);
        config = cache.get(key);
        return (T) config.get();
    }
</code></pre>

<p>而<code>config.get()</code>的时候，实际上会调用内部的各种初始化的代码。</p>

<p>但是，这里接口设计有一个自相矛盾的地方。怎么讲了，因为“<code>ReferenceConfig</code> 实例很重”，所以，<code>ReferenceConfigCache</code>帮我们做了缓存，但是使用的时候，接口的设计却只能接受一个<code>ReferenceConfig</code> 对象，那这个对象从何而来呢？也就是说，这个缓存其实只能给Dubbo内部使用——用户给一个<code>ReferenceConfig</code> 对象给Dubbo，Dubbo判断这个对象是不是和以前的对象等价，等价的话我就不用用户传递的，用以前创建好的（因为这个对象各种资源都创建好了，没必要重复创建）。</p>

<h2>原因呼之欲出</h2>

<p>分析到这里，其实这个问题的原因已经呼之欲出了：因为泛化调用而创建了<code>ReferenceConfig</code> 对象。实际上，要复现这个问题，只需要模拟不断创建临时<code>ReferenceConfig</code> 变量然后触发GC即可：</p>

<pre><code class="java">for (int i = 0; i&lt;100000;i++) {
    new ReferenceConfig&lt;&gt;();
}
System.gc();//手动触发一下GC，确保上面创建的ReferenceConfig能触发GC回收
</code></pre>

<p>运行以上代码，你能发现和本文开头一模一样的告警日志。</p>

<h2>为什么是ReferenceConfig(null)，即URL为什么是null？</h2>

<p>你可能会问，上面的分析原因是清楚了，但是为什么ReferenceConfig打印的时候，url参数总是显示null? 其实上面的分析已经回答这个问题了。上面章节我们提到“而<code>config.get()</code>的时候，实际上会调用内部的各种初始化的代码。”而这个初始化的过程之一就是构建合适的url，所以当我们使用<code>`ReferenceConfigCache</code>做泛化调用的时候，除了第一次创建的ReferenceConfig被<code>ReferenceConfigCache</code>缓存起来并初始化了，其他的对象其实都没有初始化过，那自然URL就是空了，同时又因为没有被缓存（所以对象在方法运行结束后不可达了）必然后面会被触发GC，那日志看起来就是ReferenceConfig(null)。</p>

<p>实际上分析到这里，我们可以看出这里Dubbo有两个处理不好的地方</p>

<ol>
<li>API设计不合理——认为ReferenceConfig很重需要缓存，但是使用的时候必须要提供一个对象</li>
<li>ReferenceConfig回收的告警上，其实是存在优化空间的，像这种没有初始化过的对象，其实没必要打WARN日志，毕竟他没有初始化过就自然没有什么可destroy的</li>
</ol>


<h2>解决方案</h2>

<p>从这里分析可以看到这行告警其实是”误报“，只要日志里url显示是null，并没有什么特殊的实际影响（在不考虑上文讲的GC问题的前提下）</p>

<pre><code class="java">[DUBBO] ReferenceConfig(null) is not DESTROYED when FINALIZE，dubbo version 2.6.2
</code></pre>

<p>那如果要修复这个告警，则可考虑显示的缓存<code>ReferenceConfig</code>对象，不要每次泛化调用的时候都创建一个，可参考以下代码：</p>

<pre><code class="java">    private synchronized ReferenceConfig&lt;GenericService&gt; getOrNewReferenceConfig(String interfaceClass) {
        String refConfigCacheKey = interfaceClass;
        WeakReference&lt;ReferenceConfig&lt;GenericService&gt;&gt; referenceConfigWeakReference = refConfigCache.get(refConfigCacheKey);

        if (referenceConfigWeakReference != null) {//缓存有弱引用
            ReferenceConfig&lt;GenericService&gt; referenceConfigFromWR = referenceConfigWeakReference.get();
            if (referenceConfigFromWR == null) {//证明没人引用自己被GC了，需要重建
                ReferenceConfig&lt;GenericService&gt; referenceConfig = newRefConifg(interfaceClass);
                refConfigCache.put(refConfigCacheKey, new WeakReference&lt;&gt;(referenceConfig));//放入缓存中，用弱应用hold住，不影响该有GC
                return referenceConfig;
            } else {
                return referenceConfigFromWR;
            }

        } else {//缓存没有，则创建
            ReferenceConfig&lt;GenericService&gt; referenceConfig = newRefConifg(interfaceClass);
            refConfigCache.put(refConfigCacheKey, new WeakReference&lt;&gt;(referenceConfig));//放入缓存中，用弱应用hold住，不影响该有GC
            return referenceConfig;
        }
    }
</code></pre>

<p>注：</p>

<ol>
<li>其中newRefConifg即为原先的创建<code>ReferenceConfig</code>的代码</li>
<li>之所以使用<code>WeakReference</code>是为了保证这个缓存的对象不会影响GC——即该回收的时候还是得回收</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[优雅地处理重复请求（并发请求）——附Java实现]]></title>
    <link href="https://Jaskey.github.io/blog/2020/05/19/handle-duplicate-request/"/>
    <updated>2020-05-19T19:52:01+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/05/19/handle-duplicate-request</id>
    <content type="html"><![CDATA[<p>对于一些用户请求，在某些情况下是可能重复发送的，如果是查询类操作并无大碍，但其中有些是涉及写入操作的，一旦重复了，可能会导致很严重的后果，例如交易的接口如果重复请求可能会重复下单。</p>

<p>重复的场景有可能是：</p>

<ol>
<li>黑客拦截了请求，重放</li>
<li>前端/客户端因为某些原因请求重复发送了，或者用户在很短的时间内重复点击了。</li>
<li>网关重发</li>
<li>&hellip;.</li>
</ol>


<p>本文讨论的是如果在服务端优雅地统一处理这种情况，如何禁止用户重复点击等客户端操作不在本文的讨论范畴。</p>

<h2>利用唯一请求编号去重</h2>

<p>你可能会想到的是，只要请求有唯一的请求编号，那么就能借用Redis做这个去重——只要这个唯一请求编号在redis存在，证明处理过，那么就认为是重复的</p>

<p>代码大概如下：</p>

<pre><code class="java">        String KEY = "REQ12343456788";//请求唯一编号
        long expireTime =  1000;// 1000毫秒过期，1000ms内的重复请求会认为重复
        long expireAt = System.currentTimeMillis() + expireTime;
        String val = "expireAt@" + expireAt;

        //redis key还存在的话要就认为请求是重复的
        Boolean firstSet = stringRedisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; connection.set(KEY.getBytes(), val.getBytes(), Expiration.milliseconds(expireTime), RedisStringCommands.SetOption.SET_IF_ABSENT));

        final boolean isConsiderDup;
        if (firstSet != null &amp;&amp; firstSet) {// 第一次访问
            isConsiderDup = false;
        } else {// redis值已存在，认为是重复了
            isConsiderDup = true;
        }
</code></pre>

<h2>业务参数去重</h2>

<p>上面的方案能解决具备唯一请求编号的场景，例如每次写请求之前都是服务端返回一个唯一编号给客户端，客户端带着这个请求号做请求，服务端即可完成去重拦截。</p>

<p>但是，很多的场景下，请求并不会带这样的唯一编号！那么我们能否针对请求的参数作为一个请求的标识呢？</p>

<p>先考虑简单的场景，假设请求参数只有一个字段reqParam，我们可以利用以下标识去判断这个请求是否重复。 <strong>用户ID:接口名:请求参数</strong></p>

<pre><code class="java">    String KEY = "dedup:U="+userId + "M=" + method + "P=" + reqParam;
</code></pre>

<p>那么当同一个用户访问同一个接口，带着同样的reqParam过来，我们就能定位到他是重复的了。</p>

<p>但是问题是，我们的接口通常不是这么简单，以目前的主流，我们的参数通常是一个JSON。那么针对这种场景，我们怎么去重呢？</p>

<h3>计算请求参数的摘要作为参数标识</h3>

<p>假设我们把请求参数（JSON）按KEY做升序排序，排序后拼成一个字符串，作为KEY值呢？但这可能非常的长，所以我们可以考虑对这个字符串求一个MD5作为参数的摘要，以这个摘要去取代reqParam的位置。</p>

<pre><code class="java">    String KEY = "dedup:U="+userId + "M=" + method + "P=" + reqParamMD5;
</code></pre>

<p>这样，请求的唯一标识就打上了！</p>

<p>注：MD5理论上可能会重复，但是去重通常是短时间窗口内的去重（例如一秒），一个短时间内同一个用户同样的接口能拼出不同的参数导致一样的MD5几乎是不可能的。</p>

<h3>继续优化，考虑剔除部分时间因子</h3>

<p>上面的问题其实已经是一个很不错的解决方案了，但是实际投入使用的时候可能发现有些问题：某些请求用户短时间内重复的点击了（例如1000毫秒发送了三次请求），但绕过了上面的去重判断（不同的KEY值）。</p>

<p>原因是这些请求参数的字段里面，<strong>是带时间字段的</strong>，这个字段标记用户请求的时间，服务端可以借此丢弃掉一些老的请求（例如5秒前）。如下面的例子，请求的其他参数是一样的，除了请求时间相差了一秒：</p>

<pre><code class="java">        //两个请求一样，但是请求时间差一秒
        String req = "{\n" +
                "\"requestTime\" :\"20190101120001\",\n" +
                "\"requestValue\" :\"1000\",\n" +
                "\"requestKey\" :\"key\"\n" +
                "}";

        String req2 = "{\n" +
                "\"requestTime\" :\"20190101120002\",\n" +
                "\"requestValue\" :\"1000\",\n" +
                "\"requestKey\" :\"key\"\n" +
                "}";
</code></pre>

<p>这种请求，我们也很可能需要挡住后面的重复请求。所以求业务参数摘要之前，需要剔除这类时间字段。还有类似的字段可能是GPS的经纬度字段（重复请求间可能有极小的差别）。</p>

<h2>请求去重工具类，Java实现</h2>

<pre><code class="java">public class ReqDedupHelper {

    /**
     *
     * @param reqJSON 请求的参数，这里通常是JSON
     * @param excludeKeys 请求参数里面要去除哪些字段再求摘要
     * @return 去除参数的MD5摘要
     */
    public String dedupParamMD5(final String reqJSON, String... excludeKeys) {
        String decreptParam = reqJSON;

        TreeMap paramTreeMap = JSON.parseObject(decreptParam, TreeMap.class);
        if (excludeKeys!=null) {
            List&lt;String&gt; dedupExcludeKeys = Arrays.asList(excludeKeys);
            if (!dedupExcludeKeys.isEmpty()) {
                for (String dedupExcludeKey : dedupExcludeKeys) {
                    paramTreeMap.remove(dedupExcludeKey);
                }
            }
        }

        String paramTreeMapJSON = JSON.toJSONString(paramTreeMap);
        String md5deDupParam = jdkMD5(paramTreeMapJSON);
        log.debug("md5deDupParam = {}, excludeKeys = {} {}", md5deDupParam, Arrays.deepToString(excludeKeys), paramTreeMapJSON);
        return md5deDupParam;
    }

    private static String jdkMD5(String src) {
        String res = null;
        try {
            MessageDigest messageDigest = MessageDigest.getInstance("MD5");
            byte[] mdBytes = messageDigest.digest(src.getBytes());
            res = DatatypeConverter.printHexBinary(mdBytes);
        } catch (Exception e) {
            log.error("",e);
        }
        return res;
    }
}
</code></pre>

<p>下面是一些测试日志：</p>

<pre><code class="java">    public static void main(String[] args) {
        //两个请求一样，但是请求时间差一秒
        String req = "{\n" +
                "\"requestTime\" :\"20190101120001\",\n" +
                "\"requestValue\" :\"1000\",\n" +
                "\"requestKey\" :\"key\"\n" +
                "}";

        String req2 = "{\n" +
                "\"requestTime\" :\"20190101120002\",\n" +
                "\"requestValue\" :\"1000\",\n" +
                "\"requestKey\" :\"key\"\n" +
                "}";

        //全参数比对，所以两个参数MD5不同
        String dedupMD5 = new ReqDedupHelper().dedupParamMD5(req);
        String dedupMD52 = new ReqDedupHelper().dedupParamMD5(req2);
        System.out.println("req1MD5 = "+ dedupMD5+" , req2MD5="+dedupMD52);

        //去除时间参数比对，MD5相同
        String dedupMD53 = new ReqDedupHelper().dedupParamMD5(req,"requestTime");
        String dedupMD54 = new ReqDedupHelper().dedupParamMD5(req2,"requestTime");
        System.out.println("req1MD5 = "+ dedupMD53+" , req2MD5="+dedupMD54);

    }
</code></pre>

<p>日志输出：</p>

<pre><code class="java">req1MD5 = 9E054D36439EBDD0604C5E65EB5C8267 , req2MD5=A2D20BAC78551C4CA09BEF97FE468A3F
req1MD5 = C2A36FED15128E9E878583CAAAFEFDE9 , req2MD5=C2A36FED15128E9E878583CAAAFEFDE9
</code></pre>

<p>日志说明：</p>

<ul>
<li>一开始两个参数由于requestTime是不同的，所以求去重参数摘要的时候可以发现两个值是不一样的</li>
<li>第二次调用的时候，去除了requestTime再求摘要（第二个参数中传入了&#8221;requestTime&#8221;），则发现两个摘要是一样的，符合预期。</li>
</ul>


<h2>总结</h2>

<p>至此，我们可以得到完整的去重解决方案，如下：</p>

<pre><code class="java">    String userId= "12345678";//用户
    String method = "pay";//接口名
    String dedupMD5 = new ReqDedupHelper().dedupParamMD5(req,"requestTime");//计算请求参数摘要，其中剔除里面请求时间的干扰
    String KEY = "dedup:U=" + userId + "M=" + method + "P=" + dedupMD5;

    long expireTime =  1000;// 1000毫秒过期，1000ms内的重复请求会认为重复
    long expireAt = System.currentTimeMillis() + expireTime;
    String val = "expireAt@" + expireAt;

    // NOTE:直接SETNX不支持带过期时间，所以设置+过期不是原子操作，极端情况下可能设置了就不过期了，后面相同请求可能会误以为需要去重，所以这里使用底层API，保证SETNX+过期时间是原子操作
    Boolean firstSet = stringRedisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; connection.set(KEY.getBytes(), val.getBytes(), Expiration.milliseconds(expireTime),
            RedisStringCommands.SetOption.SET_IF_ABSENT));

    final boolean isConsiderDup;
    if (firstSet != null &amp;&amp; firstSet) {
        isConsiderDup = false;
    } else {
        isConsiderDup = true;
    }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用Java进程名进行jstat -gc]]></title>
    <link href="https://Jaskey.github.io/blog/2020/05/13/stat-gc-with-process-name/"/>
    <updated>2020-05-13T16:29:07+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/05/13/stat-gc-with-process-name</id>
    <content type="html"><![CDATA[<p>需要实时观看GC的情况，我们可以类似如下命令进行监控</p>

<pre><code class="bash"> jstat -gc $pid 100 10 
</code></pre>

<p>但是这里需要一个进程号，很麻烦，每个Java进程在不同机器或者启动不一样就会不一样，对于自动监控脚本或者是如果需要定位应用刚开始启动时候gc的问题时，当你手动敲完命令拿到pid的时候，可能都凉了。</p>

<p>对此写了一个简单的shell脚本可以传入进程名去执行jstat</p>

<p>gcstat.sh:</p>

<pre><code class="bash">#! /bin/bash

process=$1
interval=$2
count=$3
pid=$(ps -ef | grep java | grep $process | grep -v grep | awk '{print $2}') 
echo $pid
echo $interval
echo $count
</code></pre>

<p>使用：</p>

<pre><code class="bash">./gcstat.sh  processName 1000 5
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[自定义ShardingSphere的加解密器]]></title>
    <link href="https://Jaskey.github.io/blog/2020/04/29/user-defined-shardingsphere-encryptor/"/>
    <updated>2020-04-29T20:44:03+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/04/29/user-defined-shardingsphere-encryptor</id>
    <content type="html"><![CDATA[<p>默认的Sharding Sphere 支持AES和MD5两种加密器。有些时候可能需要自定义使用自己的加解密算法，如AES的具体实现不一样等。网上公开的并没有直接的指引，通过部分源码的阅读，找到了可行的方式。需要三步：</p>

<h2>1.实现自定义解密器 （实现ShardingEncryptor 接口）</h2>

<pre><code class="java">public class TestShardingEncryptor implements ShardingEncryptor {
        private Properties properties = new Properties();

         @Override
         public String getType() {
                return "TEST";
          }


          @Override
         public void init() {

         }

         @Override
         public String encrypt(final Object plaintext) {
             return "TEST-"+String.valueOf(plaintext);
         }

         @Override
        public Object decrypt(final String ciphertext) {
             return ciphertext.replaceAll("TEST-","");
         }
}
</code></pre>

<p>其中<code>getType</code>返回的字符串（本例为&#8221;TEST&#8221;）即为本加解密器的类型（后续使用的时候会使用）</p>

<h2>2.创建org.apache.shardingsphere.spi.encrypt.ShardingEncryptor 文件</h2>

<p>需要创建一个文件名为<code>org.apache.shardingsphere.spi.encrypt.ShardingEncryptor</code>放入resources路径下的<code>\META-INF\services</code></p>

<p><img src="http://jaskey.github.io/images/shardingsphere/sharding-encryptor-file-path.png" title="sharding-encryptor-file-path" alt="sharding-encryptor-file-path" /></p>

<p>文件的内容就是类名全称，如：</p>

<p>com.yourcompany.TestShardingEncryptor</p>

<h2>3.配置使用此自定义类</h2>

<h4>Java配置模式：</h4>

<p>如果未使用Spring Boot，需要显示用代码配置</p>

<pre><code class="java">EncryptorRuleConfiguration encryptorConfig = new EncryptorRuleConfiguration("TEST", props);
</code></pre>

<h4>Spring Boot配置模式：</h4>

<p>如果使用的是Spring Boot配置模式，则需要如下配置</p>

<pre><code class="java">spring.shardingsphere.encrypt.encryptors.my_encryptor.type=TEST  
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java GC垃圾收集器这点小事]]></title>
    <link href="https://Jaskey.github.io/blog/2020/04/27/gc-basics/"/>
    <updated>2020-04-27T15:08:05+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/04/27/gc-basics</id>
    <content type="html"><![CDATA[<p>​    对于大多数的应用来说，其实默认的JVM设置就够用了，但当你意识到有GC引起的性能问题、并且仅仅加大堆内存空间也解决不了的时候，那你就应该考虑下GC的调优了。但对于大多数程序员来说，这是很麻烦的，因为调优需要很多耐心，并且需要知道垃圾回收器的运作原理及背后对应用的影响。本文是high-level层面的关于Java垃圾回收器的总览，并以例子的形式去讲解性能定位的一些问题。</p>

<p>​    正文开始。</p>

<p>​    Java提供了很多种垃圾回收器，会在gc运行的线程中搭配着不同的算法。不同的回收器工作原理不一样，优缺点也不同。最重要的是无论哪一种回收器都会&#8221;stop the world&#8221;。就是说，在收集和回收的过程中，你的应用程序（或多或少）都会处于暂停状态，只不过不同算法的stop the world的表现有所不同。有些算法一直都会闲置不工作直到必须要垃圾收集才开始工作，然后就暂停应用程序很长的时间；而有一些则能和应用程序同步的进行所以在“stop the world”阶段就会有更少的暂停。选择最合适的算法要取决于你的目标：你是想优化整体的吞吐量即便不时地就会长时间暂停也是可以接受的，还是说你是想得到低延迟的优化通过分散各个时间以得到每时每刻都低延迟。</p>

<p>​    为了增强垃圾回收的过程，Java（准确的说是 HotSpot JVM）把堆分成了两个代，年轻代和年老代（还有一个叫永久代的区域不在我们本文讨论范围）</p>

<p><img src="http://jaskey.github.io/images/gc/hotspot-heap.png" title="hotspot-heap" alt="hotspot-heap" /></p>

<p>​    年轻代是一些“年轻”的对象存放的地方，而年轻代还会继续分为以下三个区域：</p>

<ol>
<li>伊甸区（Eden Space）</li>
<li>幸存区1（Survivor Space 1）</li>
<li>幸存区2（Survivor Space 2）</li>
</ol>


<p>​    默认情况下，伊甸区是大于两个幸存者区的总和的。例如在我的Mac OS X上的64位HotSpot JVM上，伊甸区占了大概年轻代76%的区域。所有的对象一开始都会在伊甸区创建，当伊甸区满了之后，就会触发一次次要的垃圾回收（minor gc），期间新对象会快速地被检查是否可以进行垃圾回收。一旦发现那些对象已经死亡（dead），也就是说没有再被其他对象引用了（这里先简单忽略掉引用的具体类型带来的一些差异，不在本文讨论），就会被标记为死亡然后被垃圾回收掉。而其中“幸存”的对象就会被移到其中的一个空的Survivor Space。你可能会问，具体移动到哪一个幸存区呢？要回答这个问题，首先我们先聊一下幸存区的设计。</p>

<p>​    之所以设计两个幸存区，是为了避免内存碎片。假设只有一个幸存区（然后我们把幸存区想象成一个内存中连续的数组），当年轻代的gc在这个数组上运行了一遍后，会标记一些死亡对象然后删除掉，这样的话势必会在内存中留下一些空洞的区域（原来的对象存活的位置），那么就有必要做压缩了。所以为了避免做压缩，HotSpot JVM就从一个幸存者区复制所有幸存的对象到另外一个（空的）幸存者区里，这样就没有空洞了。这里我们讲到了压缩，顺便提一下年老代的垃圾回收器（除了CMS）在进行年老代垃圾回收的时候都会进行压缩以避免内存碎片。</p>

<p>​    简单地说，次要的垃圾回收（当伊甸区满的时候）就会把存活的对象从伊甸区和其中一个幸存区（gc日志中以“from”呈现）左右捣腾地搬到另外一个幸存区（又叫“to”）。这样会一直的持续下去直到以下的条件发生：</p>

<ol>
<li>对象达到了最大的晋升时间阈值（<em>maximum tenuring threshold</em>），就是说在年轻代被左右捣腾得足够久了，媳妇熬成婆。</li>
<li>幸存区已经没有空间去接受新生的对象了（后面会讲到）</li>
</ol>


<p>​    以上条件发生后，对象就会被移动到年老代了。下面用一个具体的例子来理解下。假设我们有以下的应用程序，它会在初始化的时候创建一些长期存活的对象，也会在运行的过程中不断的创建很多存活时间很短的对象（例如我们的web服务器程序在处理请求的时候会不断分配存活时间很短的对象）</p>

<pre><code class="java">private static void createFewLongLivedAndManyShortLivedObjects() {
        HashSet&lt;Double&gt; set = new HashSet&lt;Double&gt;();

        long l = 0;
        for (int i=0; i &lt; 100; i++) {
            Double longLivedDouble = new Double(l++);
            set.add(longLivedDouble);  // 加到集合里，让这些对象能持续的存活
        }

        while(true) { // 不断地创建一些存活时间短的对象（这里在实际代码中比较极端，仅为演示用）
            Double shortLivedDouble = new Double(l++);
        }
}
</code></pre>

<p> 在运行这个程序的过程中我们启用GC的部分日志参数：</p>

<pre><code class="java">-Xmx100m                     // 分配100MV的堆内存
-XX:-PrintGC                 // 开启GC日志打印
-XX:+PrintHeapAtGC           // 开启GC日志打印堆信息
-XX:MaxTenuringThreshold=15  // 为了让对象能在年轻代呆久一点
-XX:+UseConcMarkSweepGC      // 暂时先忽略这个配置，后面会讲到
-XX:+UseParNewGC             // 暂时先忽略这个配置，后面会讲到
</code></pre>

<p>gc 日志会显示垃圾收集前后的情况如下：</p>

<pre><code class="html">Heap &lt;b&gt;before&lt;/b&gt; GC invocations=5 (full 0):
 par new (&lt;u&gt;young&lt;/u&gt;) generation total 30720K, used 28680K
  eden space 27328K,   &lt;b&gt;100%&lt;/b&gt; used
  from space 3392K,   &lt;b&gt;39%&lt;/b&gt; used
  to   space 3392K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 68288K, used &lt;b&gt;0K&lt;/b&gt; &lt;br/&gt;
Heap &lt;b&gt;after&lt;/b&gt; GC invocations=6 (full 0):
 par new generation (&lt;u&gt;young&lt;/u&gt;) total 30720K, used 1751K
  eden space 27328K,   &lt;b&gt;0%&lt;/b&gt; used
  from space 3392K,   &lt;b&gt;51%&lt;/b&gt; used
  to   space 3392K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 68288K, used &lt;b&gt;0K&lt;/b&gt;
</code></pre>

<p>​    从这个日志里我们能得到以下信息。第一，在这次gc之前，已经发生了5次的minor gc了（所以这次是第6次）。第二，伊甸区占用了100%所以触发了这次的gc。第三，其中一个幸存区域已经使用了39%的空间（还有不少可用空间）。而这次垃圾收集结束后，我们能看到伊甸区就被清空了（0%）然后幸存者区域上升到51%。这意味着伊甸区和其中一个幸存区里存活的对象已经被移动到另外一个幸存区了，然后死亡的对象已经被垃圾回收了。怎么推断的死亡对象被回收了呢？我们看到伊甸区原来是比幸存区要大的（27328K vs 3392K），而后面幸存区的空间大小仅仅是轻微的上升（伊甸区被清空了），所以大量的对象肯定是被垃圾回收了。而我们再看看年老代，年老代是一直都是空的，无论是这次垃圾回收前还是后（回想一下，我们设置了晋升阈值为15）。</p>

<p>​    下面我们再试另外一个实验。这次用多线程不断的创建存活时间很短的对象。直觉上判断，依旧应该没有对象会上升到年老代才对，因为minor gc就应该可以把这些对象清理干净。我们来看看实际情况如何</p>

<pre><code class="java">private static void createManyShortLivedObjects() {
        final int NUMBER_OF_THREADS = 100;
        final int NUMBER_OF_OBJECTS_EACH_TIME = 1000000;

        for (int i=0; i&lt;NUMBER_OF_THREADS; i++) {
            new Thread(() -&gt; {
                    while(true) {
                        for (int i=0; i&lt;NUMBER_OF_OBJECTS_EACH_TIME; i++) {
                            Double shortLivedDouble = new Double(1.0d);
                        }
                        sleepMillis(1);
                    }
                }
            }).start();
        }
    }
}
</code></pre>

<p>这次，我们只给10MB的内存，然后看看GC日志</p>

<pre><code class="java">Heap &lt;b&gt;before&lt;/b&gt; GC invocations=0 (full 0):
 par new (&lt;u&gt;young&lt;/u&gt;) generation total 3072K, used 2751K
  eden space 2752K,  99% used
  from space 320K,   0% used
  to   space 320K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 6848K, used &lt;b&gt;0K&lt;/b&gt; &lt;br/&gt;
Heap &lt;b&gt;after&lt;/b&gt; GC invocations=1 (full 0):
 par new generation  (&lt;u&gt;young&lt;/u&gt;)  total 3072K, used 318K
  eden space 2752K,   0% used
  from space 320K,  99% used
  to   space 320K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 6848K, used &lt;b&gt;76K&lt;/b&gt;
</code></pre>

<p>​    从日志上看，并不如我们一开始想的那样。这次，老年代在第一次minor gc之后，接受了一些对象。实际上这些对象都是存活时间很短的对象，并且我们设置了晋升阈值是15次，再而且日志里显示的gc只是第一次垃圾收集。这个现象背后实际上是这样的：应用程序创建了大量的对象在伊甸区，minor gc启动的时候尝试去回收，但是大多数的这些存活时间很短的对象实际上都是active的（被一个运行中的线程引用着）。那么年轻代的垃圾收集器就只好把这些对象移动到年老代了。这其实是一个不好的现象，因为这些被移到到年老代的对象其实是过早衰老了（prematurely aged），它们只有在老年代的major gc才能被回收，而major gc通常会耗时更长。对于某些垃圾算法例如CMS，major gc会在年老代70%内存占据后出发。这个值可以通过参数修改<code>-XX:CMSInitiatingOccupancyFraction=70</code></p>

<p>​    怎么样防止这些短暂存活的对象过早衰老呢？有几个方法，其中一个理论上可行的方法是估计这些活跃的短暂存活对象的数量，然后设置合理的年轻代大小。我们下面来试试：</p>

<ul>
<li>年轻代默认是整个堆大小的1/3，这次我们通过 <code>-XX:NewRatio=1</code> 来修改其大小让他内存更大些（大约3.4MB，原来是3MB）</li>
<li>同时调整幸存者区的大小：<code>-XX:SurvivorRatio=1</code> （大约1.6MB一个区，原来是0.3MB）</li>
</ul>


<p>问题就解决了。经过8次的minor gc，年老代依旧是空的</p>

<pre><code class="html">Heap &lt;b&gt;before&lt;/b&gt; GC invocations=7 (full 0):
 par new generation   total 3456K, used 2352K
  eden space 1792K,  99% used
  from space 1664K,  33% used
  to   space 1664K,   0% used
 concurrent mark-sweep generation total 5120K, used &lt;b&gt;0K&lt;/b&gt; &lt;br/&gt;
Heap &lt;b&gt;after&lt;/b&gt; GC invocations=8 (full 0):
 par new generation   total 3456K, used 560K
  eden space 1792K,   0% used
  from space 1664K,  33% used
  to   space 1664K,   0% used [
 concurrent mark-sweep generation total 5120K, used &lt;b&gt;0K&lt;/b&gt;
</code></pre>

<p>​    对于GC调优，没有银弹。这里只是简单地示意。对于实际的应用，需要不断的修改配置试错来找到最佳配置。例如，这次其实我们也可以将堆的总大小调大一倍来解决此问题。</p>

<h2>垃圾回收算法</h2>

<p>​    接下来我们来看看具体的垃圾回收算法。Hotspot JVM针对年轻代和年老代有多个不同的算法。从宏观层面上看，有三种类型的垃圾回收算法，每一类都有单独的<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/collectors.html">性能特性</a>:</p>

<p><strong>serial collector</strong> ：使用一条线程进行所有的垃圾回收工作，相对来说也是高效的因为没有线程之间的通信。适用于单处理器的机器。使用<code>-XX:+UseSerialGC.</code>启用</p>

<p><strong>parallel collector</strong> (同时也称作吞吐回收器) ：使用多线程进行垃圾回收，这样能显著的降低垃圾回收的负荷。设计来适用于这样的应用：拥有中等或大数据集的，运行在多核处理器或多线程的硬件</p>

<p><strong>concurrent collector</strong>： 大部分的垃圾回收工作会同步的进行（不阻塞应用的运行）以维持短暂的GC暂停时间。它是设计给中等或大数据集的、响应时间比整体的吞吐量要更重要的应用，因为用这种算法去降低GC的停顿会一定程度降低应用的性能。</p>

<p><img src="http://jaskey.github.io/images/gc/gc-compared.png" title="gc-compared" alt="gc-compared" /></p>

<p>​    HotSpot JVM可以让我们选择不同的GC算法去回收年轻代和年老代，但是某些算法是需要配套的使用才兼容的。例如，你不能选择<em>Parallel Scavenge</em>去回收年轻代的同时，使用CMS收集器去回收年老代因为这两个收集器是不兼容的。以下是兼容的收集器的示意图</p>

<p><img src="http://jaskey.github.io/images/gc/gc-collectors-pairing.jpg" title="gc-collectors-pairing" alt="gc-collectors-pairing" /></p>

<ol>
<li>“Serial”是一个stop-the-world，复制算法的垃圾收集器，使用一条GC线程。</li>
<li>“Parallel Scavenge”是一个stop-the-world、采用复制算法的垃圾收集器，但是使用多条GC线程。</li>
<li>ParNew是一个stop-the-world，复制算法的收集器，使用多条GC线程。它和Parallel Scavenge的区别是它做了一些增强以适应搭配CMS使用。例如ParNew会做必要的同步（synchronization ）以便它能在CMS的同步阶段运行。</li>
<li>Serial Old 是一个stop-the-world，采用标记-清除-压缩算法的回收器，使用一条GC线程</li>
<li>CMS（Concurrent Mark Sweep）是一个同步能力最强、低延迟的垃圾回收器</li>
<li>Parallel Old是一个压缩算法的垃圾回收器，使用多个GC线程。</li>
</ol>


<p>​    对于服务端的应用程序（需要处理客户端请求）来说，使用CMS+ParNew是不错的选择。</p>

<p>我在大概10GB堆内存的程序中使用过也能保持响应时间稳定和短暂的GC暂停时间。我认识的一些开发者使用Parallel collectors (<em>Parallel Scavenge</em> + <em>Parallel Old</em>) ，效果也不错。</p>

<p>​    其中一件需要注意的事是CMS已经宣布废弃了，会被Oralce推荐使用一个新的同步收集器取代， <a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/G1.html">Garbage-First</a> 简称 <strong>G1</strong>, 一个最先由Java推出的垃圾收集器</p>

<p>​    G1是一个服务端类型（server-style）的垃圾回收器，针对多处理器、大内存的计算机使用。它能尽可能地满足一个GC延迟时间的目标，同时也有很高的吞吐量</p>

<p>​    <strong>G1</strong> 会同时在年轻代和年老代进行工作。它针对大堆有专门的优化（>10GB）。我没有亲身尝试过G1，我团队里的开发者仍然使用的CMS，所以我还不能对两者进行比较。但通过快速的搜索之后，我找到了一个性能对比说CMS会比G1更好（<a href="http://blog.novatec-gmbh.de/g1-action-better-cms/">CMS outperforming</a> <a href="https://dzone.com/articles/g1-vs-cms-vs-parallel-gc">G1</a>）。我倾向于谨慎，但G1应该是不错的。我们能靠以下参数启动</p>

<pre><code>-XX:+UseG1GC
</code></pre>

<p>注：以上由本人摘选翻译自<a href="https://codeahoy.com/2017/08/06/basics-of-java-garbage-collection/">https://codeahoy.com/2017/08/06/basics-of-java-garbage-collection/</a></p>
]]></content>
  </entry>
  
</feed>
