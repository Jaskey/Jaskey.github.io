
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>薛定谔的风口猪</title>
  <meta name="author" content="Jaskey Lam">

  
  <meta name="description" content="Jaskey的个人博客">
  <meta name="keywords" content="Java, JavaScript, js,git, css#">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://Jaskey.github.io/posts/2">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="薛定谔的风口猪" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>

  <!--linkedin source-->
  <script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">薛定谔的风口猪</a></h1>
  
    <h2>站在巨人的肩膀上学习，猪都能看得很远</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:Jaskey.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation"><!--导航栏-->
  <li><a href="/">主页</a></li>
  <li><a href="/blog/archives/">所有博文</a></li>
  <!-- <li><a href="/about" target="_blank">关于作者</a></li> &#8211;>  <!--about 文件夹下的index.html-->
  <li><a href="http://www.zhihu.com/people/linjunjie1103/answers?order_by=vote_num" target="_blank" >知乎主页</a></li><!--跳转到知乎主页-->
</ul>


</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2020/03/18/sharding-sphere-data-desensitization/">基于Sharding Sphere实现数据“一键脱敏”</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2020-03-18T20:53:00+08:00'><span class='date'>2020-03-18 Wed</span> <span class='time'>20:53</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>在真实业务场景中，数据库中经常需要存储某些客户的关键性敏感信息如：身份证号、银行卡号、姓名、手机号码等，此类信息按照合规要求，通常需要实现加密存储以满足合规要求。</p>

<h3>痛点一：</h3>

<p>通常的解决方案是我们书写SQL的时候，把对应的加密字段手动进行加密再进行插入，在查询的时候使用之前再手动进行解密。此方法固然可行，但是使用起来非常不便捷且繁琐，使得日常的业务开发与存储合规的细节紧耦合</p>

<h3>痛点二：</h3>

<p>对于一些为了快速上线而一开始没有实现合规脱敏的系统，如何比较快速的使得已有业务满足合规要求的同时，尽量减少对原系统的改造。（通常的这个过程至少包括：1.新增脱敏列的存储 2.同时做数据迁移 3.业务的代码做兼容逻辑等）。</p>

<p>Apache ShardingSphere下面存在一个数据脱敏模块，此模块集成的常用的数据脱敏的功能。其基本原理是对用户输入的SQL进行解析拦截，并依靠用户的脱敏配置进行SQL的改写，从而实现对原文字段的加密及加密字段的解密。最终实现对用户无感的加解密存储、查询。</p>

<h2>脱敏配置Quick Start——Spring 显示配置：</h2>

<p>以下介绍基于Spring如何快速让系统支持脱敏配置。</p>

<h3>1.引入依赖</h3>

<pre><code>&lt;!-- for spring namespace --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt;
    &lt;version&gt;${sharding-sphere.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<h3>2.创建脱敏配置规则对象</h3>

<p>在创建数据源之前，需要准备一个EncryptRuleConfiguration进行脱敏的配置，以下是一个例子，对于同一个数据源里两张表card_info，pay_order的不同字段进行AES的加密</p>

<pre><code>private EncryptRuleConfiguration getEncryptRuleConfiguration() {
Properties props = new Properties();

//自带aes算法需要
props.setProperty("aes.key.value", aeskey);
EncryptorRuleConfiguration encryptorConfig = new EncryptorRuleConfiguration("AES", props);

//自定义算法
//props.setProperty("qb.finance.aes.key.value", aeskey);
//EncryptorRuleConfiguration encryptorConfig = new EncryptorRuleConfiguration("QB-FINANCE-AES", props);

EncryptRuleConfiguration encryptRuleConfig = new EncryptRuleConfiguration();
encryptRuleConfig.getEncryptors().put("aes", encryptorConfig);

//START: card_info 表的脱敏配置
{
    EncryptColumnRuleConfiguration columnConfig1 = new EncryptColumnRuleConfiguration("", "name", "", "aes");
    EncryptColumnRuleConfiguration columnConfig2 = new EncryptColumnRuleConfiguration("", "id_no", "", "aes");
    EncryptColumnRuleConfiguration columnConfig3 = new EncryptColumnRuleConfiguration("", "finshell_card_no", "", "aes");
    Map&lt;String, EncryptColumnRuleConfiguration&gt; columnConfigMaps = new HashMap&lt;&gt;();
    columnConfigMaps.put("name", columnConfig1);
    columnConfigMaps.put("id_no", columnConfig2);
    columnConfigMaps.put("finshell_card_no", columnConfig3);
    EncryptTableRuleConfiguration tableConfig = new EncryptTableRuleConfiguration(columnConfigMaps);
    encryptRuleConfig.getTables().put("card_info", tableConfig);
}
//END: card_info 表的脱敏配置

//START: pay_order 表的脱敏配置
{
    EncryptColumnRuleConfiguration columnConfig1 = new EncryptColumnRuleConfiguration("", "card_no", "", "aes");
    Map&lt;String, EncryptColumnRuleConfiguration&gt; columnConfigMaps = new HashMap&lt;&gt;();
    columnConfigMaps.put("card_no", columnConfig1);
    EncryptTableRuleConfiguration tableConfig = new EncryptTableRuleConfiguration(columnConfigMaps);
    encryptRuleConfig.getTables().put("pay_order", tableConfig);
}

log.info("脱敏配置构建完成:{} ", encryptRuleConfig);
return encryptRuleConfig;
</code></pre>

<p>}</p>

<p>说明：</p>

<ol>
<li>创建 EncryptColumnRuleConfiguration 的时候有四个参数，前两个参数分表叫plainColumn、cipherColumn，其意思是数据库存储里面真实的两个列（名文列、脱敏列），对于新的系统，只需要设置脱敏列即可，所以以上示例为plainColumn为&#8221;&ldquo;。</li>
<li>创建EncryptTableRuleConfiguration 的时候需要传入一个map，这个map存的value即#1中说明的EncryptColumnRuleConfiguration ，而其key则是一个逻辑列，对于新系统，此逻辑列即为真实的脱敏列。Sharding Shpere在拦截到SQL改写的时候，会按照用户的配置，把逻辑列映射为名文列或者脱敏列（默认）如下的示例</li>
</ol>


<p><img src="http://jaskey.github.io/images/shardingsphere/basic.png" title="shardings sphere basic" alt="shardings sphere basic" /></p>

<h3>3.使用Sharding Sphere的数据源进行管理</h3>

<p>把原始的数据源包装一层</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@Bean("tradePlatformDataSource")
</span><span class='line'>public DataSource dataSource(@Qualifier("druidDataSource") DataSource ds) throws SQLException {
</span><span class='line'>    return EncryptDataSourceFactory.createDataSource(ds, getEncryptRuleConfiguration(), new Properties());
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>脱敏配置Quick Start——Spring Boot版：</h2>

<p>以下步骤使用Spring Boot管理，可以仅用配置文件解决：</p>

<p>1.引入依赖</p>

<pre><code>&lt;!-- for spring boot --&gt;

&lt;dependency&gt;
&lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;${sharding-sphere.version}&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- for spring namespace --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt;
    &lt;version&gt;${sharding-sphere.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<ol>
<li>Spring 配置文件</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>spring.shardingsphere.datasource.name=ds
</span><span class='line'>spring.shardingsphere.datasource.ds.type=com.alibaba.druid.pool.DruidDataSource
</span><span class='line'>spring.shardingsphere.datasource.ds.driver-class-name=com.mysql.jdbc.Driver
</span><span class='line'>spring.shardingsphere.datasource.ds.url=xxxxxxxxxxxxx
</span><span class='line'>spring.shardingsphere.datasource.ds.username=xxxxxxx
</span><span class='line'>spring.shardingsphere.datasource.ds.password=xxxxxxxxxxxx
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 默认的AES加密器
</span><span class='line'>spring.shardingsphere.encrypt.encryptors.encryptor_aes.type=aes
</span><span class='line'>spring.shardingsphere.encrypt.encryptors.encryptor_aes.props.aes.key.value=hkiqAXU6Ur5fixGHaO4Lb2V2ggausYwW
</span><span class='line'>
</span><span class='line'># card_info 姓名 AES加密
</span><span class='line'>spring.shardingsphere.encrypt.tables.card_info.columns.name.cipherColumn=name
</span><span class='line'>spring.shardingsphere.encrypt.tables.card_info.columns.name.encryptor=encryptor_aes
</span><span class='line'>
</span><span class='line'># card_info 身份证 AES加密
</span><span class='line'>spring.shardingsphere.encrypt.tables.card_info.columns.id_no.cipherColumn=id_no
</span><span class='line'>spring.shardingsphere.encrypt.tables.card_info.columns.id_no.encryptor=encryptor_aes
</span><span class='line'>
</span><span class='line'># card_info 银行卡号 AES加密
</span><span class='line'>spring.shardingsphere.encrypt.tables.card_info.columns.finshell_card_no.cipherColumn=finshell_card_no
</span><span class='line'>spring.shardingsphere.encrypt.tables.card_info.columns.finshell_card_no.encryptor=encryptor_aes
</span><span class='line'>
</span><span class='line'># pay_order 银行卡号 AES加密
</span><span class='line'>spring.shardingsphere.encrypt.tables.pay_order.columns.card_no.cipherColumn=card_no
</span><span class='line'>spring.shardingsphere.encrypt.tables.pay_order.columns.card_no.encryptor=encryptor_aes</span></code></pre></td></tr></table></div></figure>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2019/09/30/spring-boot-dubbo-graceful-shutdown/">SpringBoot+Dubbo优雅退出分析及方案</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2019-09-30T14:56:56+08:00'><span class='date'>2019-09-30 Mon</span> <span class='time'>14:56</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>背景：</p>

<p>当我们使用SpringBoot+D做微服务的时候，可能再服务停机的过程，发现在一瞬间出现一些报错，最典型的如比如拿到的数据库连接已经关闭等问题，如下图所示：</p>

<p><img src="http://jaskey.github.io/images/dubbo-shutdown-hook/dubbo-shutdown-problem.png" alt="img" /></p>

<p>从日志错误可以看到，停机时还存在正在处理的请求，而此请求需要访问数据源，但数据源的资源被 Spring 容器关闭了，导致获取不到而报错。</p>

<p>但是实际上，无论Dubbo和Spring其实都实现了优雅退出，为什么最后退出还是不那么优雅呢？</p>

<p>要分析这个问题，首先得分析它们两者的优雅退出实现。</p>

<h1>Dubbo优雅退出</h1>

<p>dubbo框架本身基于ShutdownHook注册了一个优雅退出的钩子，背后会调用其destroyAll来实现自身的优雅关闭。</p>

<p>以下是Dubbo 2.6.2的源码：</p>

<p><img src="http://jaskey.github.io/images/dubbo-shutdown-hook/dubbo-shutdown-sourcecode-1.png" alt="img" /></p>

<p><img src="http://jaskey.github.io/images/dubbo-shutdown-hook/dubbo-shutdown-sourcecode-2.png" alt="img" /></p>

<p>Dubbo发现程序退出的时候，钩子方法会通知注册中心取消自身的注册——以便告知消费者不要调用自己了，然后关闭自身的端口连接——在关闭自身连接的时候还会sleep自旋的方法等待已有的处理请求先完成）</p>

<p><img src="http://jaskey.github.io/images/dubbo-shutdown-hook/dubbo-shutdown-sourcecode-3.png" alt="img" /></p>

<p>但是，Dubbo服务的优雅退出，不代表服务背后的代码是优雅的，也就是说在Dubbo优雅退出的完成前，我们的服务能否能保证可用——背后的资源/服务是否仍然可用。</p>

<p>本文一开始截图的错误，原因就是服务停机的时候，依赖的数据库资源因为某些原因已经回收了，这时候正在处理的请求自然报错而显得不优雅了。</p>

<p>而回收的人并不是别人，就是Spring的优雅退出。</p>

<h1>Spring的优雅退出</h1>

<p>Spring回收资源也是基于ShutdownHook实现的，Spring在启动的时候会调用<code>refreshContext</code>接口，这个接口默认会帮我们注册优雅退出的钩子方法。</p>

<p><img src="http://jaskey.github.io/images/dubbo-shutdown-hook/spring-shutdown-hook-sourcecode-1.png" alt="img" /></p>

<p><img src="http://jaskey.github.io/images/dubbo-shutdown-hook/spring-shutdown-hook-sourcecode-2.png" alt="img" /></p>

<p>这个钩子方法最后会销毁Spring容器，其中自然包括其背后的依赖的资源。</p>

<p>因为大部分情况下，我们的Dubbo服务是依赖于Spring的资源的，要真正实现优雅退出，除了双方本身退出的过程是优雅的，还需要保证Dubbo退出的过程中Spring的资源是可用的——也就是退出应该要是有顺序的：Dubbo退出→Spring退出。</p>

<p>但是Java的ShutdownHook背后的退出是并发执行而没有顺序依赖的，这是背后表现不优雅的原因。以下是JDK文档的描述：</p>

<p><img src="http://jaskey.github.io/images/dubbo-shutdown-hook/jdk-shudownhook-coments.png" alt="img" /></p>

<p>正是由于本身应该有顺序关系的退出逻辑，在并行的处理，导致部分的流量正在处理过程中，依赖的资源已经释放了，最终导致退出的不优雅。</p>

<p>要解决这个问题，可简单可行的思路是：给Dubbo退出一定的时间去处理，然后再执行Spring容器的关闭。但由于钩子方法的时机并不能程序员控制，那么怎么样才能做到呢——禁用原生Spring的钩子方法，在合适的时机手动销毁Spring容器。</p>

<h1>优雅退出方案（简版）——给予固定睡眠时间后才关闭Spring容器：</h1>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">SpringApplication</span> <span class="n">application</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SpringApplication</span><span class="o">(</span><span class="n">Main</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class='line'><span class="n">application</span><span class="o">.</span><span class="na">setRegisterShutdownHook</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span><span class="c1">//关闭spring的shutdown hook，后续手动触发</span>
</span><span class='line'><span class="kd">final</span> <span class="n">ConfigurableApplicationContext</span> <span class="n">context</span> <span class="o">=</span> <span class="n">application</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>
</span><span class='line'><span class="n">Runtime</span><span class="o">.</span><span class="na">getRuntime</span><span class="o">().</span><span class="na">addShutdownHook</span><span class="o">(</span><span class="k">new</span> <span class="nf">Thread</span><span class="o">(</span><span class="s">&quot;T_SHUTDOWN_HOOK&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">&quot;”====================shutdown App====================“。&quot;</span><span class="o">);</span>
</span><span class='line'>        <span class="c1">//....这里可以做其他优雅退出处理，例如回收本地线程池、关闭定时调度器等的操作</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">try</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">2000</span><span class="o">);</span><span class="c1">//等待一段时间，这里给时间dubbo的shutdownhook执行，</span>
</span><span class='line'>        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">InterruptedException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">log</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="s">&quot;&quot;</span><span class="o">,</span><span class="n">e</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">//关闭spring容器</span>
</span><span class='line'>        <span class="n">context</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<h1>优雅退出方案（升级版）——动态地等待消费者及生产者连接关闭后才关闭Spring容器：</h1>

<p>上面的方案正常情况下也够用，因为大部分时间我们只需要估算一个退出时间，让dubbo处理销毁的工作即可，但是对于一些退出时间相对变化较大（如有动态的消费者），表现出来的结果就是dubbo的退出时间有时候较短，有时候缺比较长。如果直接给一个较大的睡眠时间，可能使得每次程序退出都等很久，就显得不太优雅了。</p>

<p>那么我们就可以使用一些底层的dubbo api去确认消费者和生产者的连接已经关闭，以下是一个方法用以取代上面代码片段中的sleep的语句：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="cm">/**</span>
</span><span class='line'><span class="cm"> * 等待Dubbo退出，优雅退出的shutdown hook可使用</span>
</span><span class='line'><span class="cm"> * @param sleepMillis 每次发现Dubbo没退出完就睡眠等待的毫秒数</span>
</span><span class='line'><span class="cm"> * @param sleepMaxTimes 最多睡眠的次数，避免一直dubbo退出太久卡住程序的退出，达到此次数后会不再等待</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">waitDubboShutdown</span><span class="o">(</span><span class="kt">long</span> <span class="n">sleepMillis</span><span class="o">,</span> <span class="kt">int</span> <span class="n">sleepMaxTimes</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">sleepWaitTimes</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span> <span class="n">sleepWaitTimes</span> <span class="o">&lt;</span><span class="n">sleepMaxTimes</span><span class="o">;</span> <span class="n">sleepWaitTimes</span><span class="o">++){</span><span class="c1">//如果dubbo的server没有关闭完成，会睡眠等待，最多等待三次</span>
</span><span class='line'>        <span class="n">Collection</span> <span class="n">existingDubboServers</span> <span class="o">=</span> <span class="n">DubboProtocol</span><span class="o">.</span><span class="na">getDubboProtocol</span><span class="o">().</span><span class="na">getServers</span><span class="o">();</span>
</span><span class='line'>        <span class="n">Collection</span> <span class="n">existingDubboExporters</span>  <span class="o">=</span> <span class="n">DubboProtocol</span><span class="o">.</span><span class="na">getDubboProtocol</span><span class="o">().</span><span class="na">getExporters</span><span class="o">();</span>
</span><span class='line'>        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">&quot;existing dubbo servers : {}, existing dubbo expoerters {} ,  sleepWaitTimes : {}&quot;</span><span class="o">,</span> <span class="n">existingDubboServers</span><span class="o">,</span> <span class="n">existingDubboExporters</span><span class="o">,</span> <span class="n">sleepWaitTimes</span><span class="o">);</span>
</span><span class='line'>        <span class="k">if</span> <span class="o">(!</span><span class="n">existingDubboServers</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">()</span> <span class="o">||</span> <span class="o">!</span><span class="n">existingDubboExporters</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">try</span> <span class="o">{</span>
</span><span class='line'>                <span class="n">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="n">sleepMillis</span><span class="o">);</span>
</span><span class='line'>            <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">InterruptedException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>                <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
</span><span class='line'>            <span class="o">}</span>
</span><span class='line'>        <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">break</span><span class="o">;</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">//优雅退出失败，打印日志</span>
</span><span class='line'>    <span class="n">Collection</span> <span class="n">existingDubboServers</span> <span class="o">=</span> <span class="n">DubboProtocol</span><span class="o">.</span><span class="na">getDubboProtocol</span><span class="o">().</span><span class="na">getServers</span><span class="o">();</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(!</span><span class="n">existingDubboServers</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">log</span><span class="o">.</span><span class="na">warn</span><span class="o">(</span><span class="s">&quot;DUBBO服务Server依然存在，不再等待其销毁，可能会导致优雅退出失败 {}&quot;</span><span class="o">,</span><span class="n">existingDubboServers</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">Collection</span> <span class="n">existingDubboExporters</span>  <span class="o">=</span> <span class="n">DubboProtocol</span><span class="o">.</span><span class="na">getDubboProtocol</span><span class="o">().</span><span class="na">getExporters</span><span class="o">();</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(!</span><span class="n">existingDubboExporters</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">log</span><span class="o">.</span><span class="na">warn</span><span class="o">(</span><span class="s">&quot;DUBBO服务Exporters依然存在，不再等待其销毁，可能会导致优雅退出失败 {}&quot;</span><span class="o">,</span><span class="n">existingDubboExporters</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>注：这个方法用到了DubboProtocol的底层API，所以如果你的协议不是使用&#8221;dubbo&#8221;而是如HTTP协议、redis协议，则此方法不可用。关于协议的部分，可以参考官方文档：<a href="http://dubbo.apache.org/zh-cn/docs/user/references/protocol/introduction.html">http://dubbo.apache.org/zh-cn/docs/user/references/protocol/introduction.html</a></p>

<p>那么最后，升级版的优雅退出代码则如下所示：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">SpringApplication</span> <span class="n">application</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SpringApplication</span><span class="o">(</span><span class="n">Main</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class='line'><span class="n">application</span><span class="o">.</span><span class="na">setRegisterShutdownHook</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span><span class="c1">//关闭spring的shutdown hook，后续手动触发</span>
</span><span class='line'><span class="kd">final</span> <span class="n">ConfigurableApplicationContext</span> <span class="n">context</span> <span class="o">=</span> <span class="n">application</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>
</span><span class='line'><span class="n">Runtime</span><span class="o">.</span><span class="na">getRuntime</span><span class="o">().</span><span class="na">addShutdownHook</span><span class="o">(</span><span class="k">new</span> <span class="nf">Thread</span><span class="o">(</span><span class="s">&quot;T_SHUTDOWN_HOOK&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">&quot;”====================shutdown App====================“。&quot;</span><span class="o">);</span>
</span><span class='line'>        <span class="c1">//....这里可以做其他优雅退出处理，例如回收本地线程池、关闭定时调度器等的操作</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">waitDubboShutdown</span><span class="o">(</span><span class="mi">1000</span><span class="o">,</span><span class="mi">5</span><span class="o">);</span><span class="c1">//每次等1000ms，最多等5次；优雅退出时间是动态的（可能1秒就能优雅退出完毕）；但如果退出时间大于5秒，那么则放弃优雅退出，直接退出。</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">//关闭spring容器</span>
</span><span class='line'>        <span class="n">context</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2019/09/23/spring-boot-tomcat-mertic/">监控Spring Boot中的Tomcat性能数据</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2019-09-23T14:56:56+08:00'><span class='date'>2019-09-23 Mon</span> <span class='time'>14:56</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>现在，我们经常会使用Spring Boot以开发Web服务，其内嵌容器的方法的确使得开发效率大大提升。</p>

<p>由于网关层通常是直接面对用户请求的一层，也是微服务里面最上游的一个服务，其请求量通常是所有服务中最大的，如果服务出现了性能上的问题，网关层通常都会出现阻塞、超时等现象，这时候就很可能需要性能的调优，其中最常见的则是参数调优。但如何知道哪些性能参数成为了瓶颈（如容器线程数是否不足等），则是调优的前提条件。</p>

<p>本文总结介绍如何在使用了Spring  Boot的前提下，获取运行时的Tomcat性能运行情况。</p>

<p>Spring Boot中有一个Spring Boot actuator的模块，用来监控和管理应用的运行状态，例如健康状况，线程运行情况等。</p>

<p>Maven 依赖：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;dependencies&gt;
</span><span class='line'>    &lt;dependency&gt;
</span><span class='line'>    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
</span><span class='line'>    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
</span><span class='line'>    &lt;/dependency&gt;
</span><span class='line'>&lt;/dependencies&gt;</span></code></pre></td></tr></table></div></figure>


<p>然后当Spring Boot运行之后，Spring Boot会有很多服务暴露在http服务中，这些服务叫EndPoints， 通过 <a href="http://">http://</a>{应用路径}/actuator 这个 url 即可访问，例如  <a href="http://">http://</a>{应用路径}/actuator/info， <a href="http://">http://</a>{应用路径}/actuator/health 这两个endpoints是默认开启的。</p>

<p>其中actuator这个路径可以通过配置修改：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>management.endpoints.web.base-path=/mypath</span></code></pre></td></tr></table></div></figure>


<p>以下是获取健康状态的一个例子：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl 'http://localhost:8080/actuator/health' -i -X GET</span></code></pre></td></tr></table></div></figure>


<p>可能会得到类似这样的结果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>    "status" : "UP"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>比较简陋，如果希望这个接口有更多数据，可以尝试这样的配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>management.endpoint.health.show-details=always</span></code></pre></td></tr></table></div></figure>


<p>结果就会丰富了（我的应用用了Redis）：类似</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "status": "UP",
</span><span class='line'>  "details": {
</span><span class='line'>      "diskSpace": {
</span><span class='line'>          "status": "UP",
</span><span class='line'>          "details": {
</span><span class='line'>              "total": 214745214976,
</span><span class='line'>              "free": 174805827584,
</span><span class='line'>              "threshold": 10485760
</span><span class='line'>          }
</span><span class='line'>      },
</span><span class='line'>      "redis": {
</span><span class='line'>          "status": "UP",
</span><span class='line'>          "details": {
</span><span class='line'>              "cluster_size": 3,
</span><span class='line'>              "slots_up": 16384,
</span><span class='line'>              "slots_fail": 0
</span><span class='line'>          }
</span><span class='line'>      }
</span><span class='line'>  }
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<p>但是这还不够，我们需要详细的容器数据。监控状况只是一部分。而这些我们想要的数据，是在一个叫metric的EndPoint下面。 但是此endpoint 默认没有暴露到http接口的的，需要添加配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#默认只开启info, health 的http暴露，在此增加metric endpoint
</span><span class='line'>management.endpoints.web.exposure.include=info, health,metric</span></code></pre></td></tr></table></div></figure>


<p>之后我们就能访问这个metric有哪些数据了</p>

<p>$ curl &lsquo;<a href="http://localhost:8080/actuator/metric">http://localhost:8080/actuator/metric</a>&rsquo; -i -X GET</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>    "names": [
</span><span class='line'>        "jvm.memory.max",
</span><span class='line'>        "jvm.threads.states",
</span><span class='line'>        "process.files.max",
</span><span class='line'>        "jvm.gc.memory.promoted",
</span><span class='line'>        "tomcat.cache.hit",
</span><span class='line'>        "tomcat.servlet.error",
</span><span class='line'>        "system.load.average.1m",
</span><span class='line'>        "tomcat.cache.access",
</span><span class='line'>        "jvm.memory.used",
</span><span class='line'>        "jvm.gc.max.data.size",
</span><span class='line'>        "jvm.gc.pause",
</span><span class='line'>        "jvm.memory.committed",
</span><span class='line'>        "system.cpu.count",
</span><span class='line'>        "logback.events",
</span><span class='line'>        "tomcat.global.sent",
</span><span class='line'>        "jvm.buffer.memory.used",
</span><span class='line'>        "tomcat.sessions.created",
</span><span class='line'>        "jvm.threads.daemon",
</span><span class='line'>        "system.cpu.usage",
</span><span class='line'>        "jvm.gc.memory.allocated",
</span><span class='line'>        "tomcat.global.request.max",
</span><span class='line'>        "tomcat.global.request",
</span><span class='line'>        "tomcat.sessions.expired",
</span><span class='line'>        "jvm.threads.live",
</span><span class='line'>        "jvm.threads.peak",
</span><span class='line'>        "tomcat.global.received",
</span><span class='line'>        "process.uptime",
</span><span class='line'>        "http.client.requests",
</span><span class='line'>        "tomcat.sessions.rejected",
</span><span class='line'>        "process.cpu.usage",
</span><span class='line'>        "tomcat.threads.config.max",
</span><span class='line'>        "jvm.classes.loaded",
</span><span class='line'>        "http.server.requests",
</span><span class='line'>        "jvm.classes.unloaded",
</span><span class='line'>        "tomcat.global.error",
</span><span class='line'>        "tomcat.sessions.active.current",
</span><span class='line'>        "tomcat.sessions.alive.max",
</span><span class='line'>        "jvm.gc.live.data.size",
</span><span class='line'>        "tomcat.servlet.request.max",
</span><span class='line'>        "tomcat.threads.current",
</span><span class='line'>        "tomcat.servlet.request",
</span><span class='line'>        "process.files.open",
</span><span class='line'>        "jvm.buffer.count",
</span><span class='line'>        "jvm.buffer.total.capacity",
</span><span class='line'>        "tomcat.sessions.active.max",
</span><span class='line'>        "tomcat.threads.busy",
</span><span class='line'>        "process.start.time"
</span><span class='line'>    ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>其中列出的是所有可以获取的监控数据，在其中我们发现了我们想要的</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>"tomcat.threads.config.max"
</span><span class='line'>"tomcat.threads.current"
</span><span class='line'>"tomcat.threads.busy"
</span></code></pre></td></tr></table></div></figure>


<p>那么如何获取其中的值呢？只需要在metric路径下加上希望获取的指标即可： curl &lsquo;<a href="http://localhost:8080/actuator/metric/tomcat.threads.busy">http://localhost:8080/actuator/metric/tomcat.threads.busy</a>&rsquo;</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "name": "tomcat.threads.busy",
</span><span class='line'>  "description": null,
</span><span class='line'>  "baseUnit": "threads",
</span><span class='line'>  "measurements": [{
</span><span class='line'>      "statistic": "VALUE",
</span><span class='line'>      "value": 1.0
</span><span class='line'>  }],
</span><span class='line'>  "availableTags": [{
</span><span class='line'>      "tag": "name",
</span><span class='line'>      "values": ["http-nio-10610"]
</span><span class='line'>  }]
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>在此，基本我们想要的数据都能实时的通过http服务接口的方式获取了，那么在流量峰值的时候，一些实时的状态便可获取到了。</p>

<h2>监控数据</h2>

<p>但是我们面对的情况是这样的，半个小时前，一个push活动带来了很大的量，但现在流量已经过去了，需要定位当时的性能问题意味着需要采集到过去的数据。所以我们可能需要一个服务定期去监控这些数据。Spring Boot已经考虑到了这种情况，所以其中有一个prometheus的模块，他是一个独立的服务去采集其中的监控数据并可视化，具体的介绍可以参考：<a href="https://www.callicoder.com/spring-boot-actuator-metrics-monitoring-dashboard-prometheus-grafana/">https://www.callicoder.com/spring-boot-actuator-metrics-monitoring-dashboard-prometheus-grafana/</a></p>

<h2>以日志形式定期输出监控数据</h2>

<p>很多时候，如果有日志的方法去定期输出监控的数据这样已经足够我们分析了。在Spring Boot 2.x里，只需要配置一个Bean</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@Configuration
</span><span class='line'>class MetricsConfig {
</span><span class='line'>    @Bean
</span><span class='line'>    LoggingMeterRegistry loggingMeterRegistry() {
</span><span class='line'>        return new LoggingMeterRegistry();
</span><span class='line'>    }
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<p>之所以需要Spring Boot版本2.x，LoggingMeterRegistry是因为是micrometer-core里面的1.10以上才引入的，而Spring Boot 1.x都低于这个版本，如果不想升级Spring Boot版本，可以尝试显示变更此版本：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;dependency&gt;
</span><span class='line'>    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;
</span><span class='line'>    &lt;artifactId&gt;micrometer-core&lt;/artifactId&gt;
</span><span class='line'>    &lt;version&gt;1.1.3&lt;/version&gt;
</span><span class='line'>&lt;/dependency&gt;
</span></code></pre></td></tr></table></div></figure>


<p>最后日志的内容就会每一分钟的打印出来：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>jvm.buffer.count{id=direct} value=26 buffers
</span><span class='line'>jvm.buffer.count{id=mapped} value=0 buffers
</span><span class='line'>jvm.buffer.memory.used{id=direct} value=632.600586 KiB
</span><span class='line'>jvm.buffer.memory.used{id=mapped} value=0 B
</span><span class='line'>jvm.buffer.total.capacity{id=direct} value=632.599609 KiB
</span><span class='line'>jvm.buffer.total.capacity{id=mapped} value=0 B
</span><span class='line'>jvm.classes.loaded{} value=12306 classes
</span><span class='line'>jvm.gc.live.data.size{} value=39.339607 MiB
</span><span class='line'>jvm.gc.max.data.size{} value=2.666992 GiB
</span><span class='line'>jvm.memory.committed{area=nonheap,id=Compressed Class Space} value=8.539062 MiB
</span><span class='line'>jvm.memory.committed{area=nonheap,id=Code Cache} value=26.8125 MiB
</span><span class='line'>jvm.memory.committed{area=heap,id=PS Survivor Space} value=30 MiB
</span><span class='line'>jvm.memory.committed{area=heap,id=PS Eden Space} value=416.5 MiB
</span><span class='line'>jvm.memory.committed{area=heap,id=PS Old Gen} value=242 MiB
</span><span class='line'>jvm.memory.committed{area=nonheap,id=Metaspace} value=66.773438 MiB
</span><span class='line'>jvm.memory.max{area=heap,id=PS Survivor Space} value=30 MiB
</span><span class='line'>jvm.memory.max{area=heap,id=PS Eden Space} value=1.272949 GiB
</span><span class='line'>jvm.memory.max{area=heap,id=PS Old Gen} value=2.666992 GiB
</span><span class='line'>jvm.memory.max{area=nonheap,id=Metaspace} value=-1 B
</span><span class='line'>jvm.memory.max{area=nonheap,id=Compressed Class Space} value=1 GiB
</span><span class='line'>jvm.memory.max{area=nonheap,id=Code Cache} value=240 MiB
</span><span class='line'>jvm.memory.used{area=nonheap,id=Code Cache} value=26.635071 MiB
</span><span class='line'>jvm.memory.used{area=heap,id=PS Survivor Space} value=25.214882 MiB
</span><span class='line'>jvm.memory.used{area=heap,id=PS Eden Space} value=46.910545 MiB
</span><span class='line'>jvm.memory.used{area=heap,id=PS Old Gen} value=39.34742 MiB
</span><span class='line'>jvm.memory.used{area=nonheap,id=Metaspace} value=63.333778 MiB
</span><span class='line'>jvm.memory.used{area=nonheap,id=Compressed Class Space} value=7.947166 MiB
</span><span class='line'>jvm.threads.daemon{} value=52 threads
</span><span class='line'>jvm.threads.live{} value=54 threads
</span><span class='line'>jvm.threads.peak{} value=67 threads
</span><span class='line'>jvm.threads.states{state=terminated} value=0 threads
</span><span class='line'>jvm.threads.states{state=blocked} value=0 threads
</span><span class='line'>jvm.threads.states{state=new} value=0 threads
</span><span class='line'>jvm.threads.states{state=runnable} value=20 threads
</span><span class='line'>jvm.threads.states{state=waiting} value=19 threads
</span><span class='line'>jvm.threads.states{state=timed-waiting} value=15 threads
</span><span class='line'>process.cpu.usage{} value=-1
</span><span class='line'>process.start.time{} value=435900h 48m 53.344s
</span><span class='line'>process.uptime{} value=56m 6.709s
</span><span class='line'>system.cpu.count{} value=8
</span><span class='line'>system.cpu.usage{} value=-1
</span><span class='line'>tomcat.global.request.max{name=http-nio-10610} value=0.597s
</span><span class='line'>tomcat.servlet.request.max{name=dispatcherServlet} value=0.567s
</span><span class='line'>tomcat.sessions.active.current{} value=0 sessions
</span><span class='line'>tomcat.sessions.active.max{} value=0 sessions
</span><span class='line'>tomcat.threads.busy{name=http-nio-10610} value=0 threads
</span><span class='line'>tomcat.threads.config.max{name=http-nio-10610} value=200 threads
</span><span class='line'>tomcat.threads.current{name=http-nio-10610} value=10 threads
</span></code></pre></td></tr></table></div></figure>


<p>如果需要修改打印的频率，可修改LoggingRegistryConfig以更改其打印频率</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  //下面是单独的配置实现的参考，当需要修改配置时候可以使用
</span><span class='line'>  return new LoggingMeterRegistry(new LoggingRegistryConfig() {
</span><span class='line'>       @Override
</span><span class='line'>     public Duration step() {
</span><span class='line'>         return Duration.ofSeconds(10);//10秒输出一次
</span><span class='line'>       }
</span><span class='line'>
</span><span class='line'>       @Override
</span><span class='line'>       public String get(String key) {
</span><span class='line'>            return null;
</span><span class='line'>       }
</span><span class='line'>   }, Clock.SYSTEM);
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/08/15/rabbitmq-delay-queue/">RabbitMQ实现延迟队列</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-08-15T14:56:56+08:00'><span class='date'>2018-08-15 Wed</span> <span class='time'>14:56</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>RabbitMQ本身没有延迟队列的支持，但是基于其本身的一些特性，可以做到类似延迟队列的效果：基于死信交换器+TTL。</p>

<p>以下介绍下相关概念及方法</p>

<h2>Dead Letter Exchanges</h2>

<p>消息在队列满足达到一定的条件，会被认为是死信消息（dead-lettered），这时候，RabbitMQ会重新把这类消息发到另外一个的exchange，这个exchange称为Dead Letter Exchanges.</p>

<p>以下任一条件满足，即可认为是死信：</p>

<ul>
<li>消息被拒绝消费(basic.reject or basic.nack)并且设置了requeue=fasle</li>
<li>消息的TTL到了（消息过期）</li>
<li>达到了队列的长度限制</li>
</ul>


<p>需要注意的是，Dead letter exchanges (DLXs) 其实就是普通的exchange，可以和正常的exchange一样的声明或者使用。</p>

<h2>死信消息路由</h2>

<p>队列中可以设置两个属性：</p>

<ul>
<li>x-dead-letter-exchange</li>
<li>x-dead-letter-routing-key</li>
</ul>


<p>当这个队列里面的消息成为死信之后，就会投递到x-dead-letter-exchange指定的exchange中，其中带着的routing key就是中指定的值x-dead-letter-routing-key。</p>

<p>而如果使用默认的exchange(routing key就是希望指定的队列)，则只需要把x-dead-letter-exchange设置为空（不能不设置），类似下面</p>

<p><img src="http://jaskey.github.io/images/rabbitmq/delay-queue-param.png" title="rabbitmq 延迟队列的配置" alt="rabbitmq 延迟队列的配置" /></p>

<p>死信消息的路由则会根据x-dead-letter-routing-key所指定的进行路由，如果这个值没有指定，则会按照消息一开始发送的时候指定的routing key进行路由</p>

<blockquote><p>Dead-lettered messages are routed to their dead letter exchange either:</p>

<p>with the routing key specified for the queue they were on; or, if this was not set,
with the same routing keys they were originally published with.</p></blockquote>

<p>例如，如果一开始你对exchange X发送消息，带着routing key &ldquo;foo&#8221;，进入了队列 Q然后消息变死信后，他会被重新发送到 dead letter exchange ，其中发给dead letter exchange带着的routing key 还是foo。 但如果这个队列Q本身是设置了x-dead-letter-routing-key  bar， 那么他发送到 dead letter exchange的时候，带着的routing key 就是bar。</p>

<p>需要注意的是，当死信消息重新路由到新的队列的时候，在死信目标队列确认收到这条死信消息之前，原来队列的消息是不会删除的，也就是说在某些异常场景下例如broker突然shutdown，是有机会存在说一个消息既存在于原队列，又存在于死信目标队列。具体可参考官方说明：</p>

<blockquote><p>Dead-lettered messages are re-published with publisher confirms turned on internally so, the &ldquo;dead-letter queues&rdquo; (DLX routing targets) the messages eventually land on must confirm the messages before they are removed from the original queue. In other words, the &ldquo;publishing&rdquo; (the one in which messages expired) queue will not remove messages before the dead-letter queues acknowledge receiving them (see Confirms for details on the guarantees made). Note that, in the event of an unclean broker shutdown, the same message may be duplicated on both the original queue and on the dead-lettering destination queues.</p></blockquote>

<h2>Time-To-Live（TTL）</h2>

<p>开头我们说过，实现延迟队列除了用死信消息外，还需要利用消息过期的TTL机制，因为只要消息过期了，就会触发死信。</p>

<p>RabbitMQ有两种方法让设置消息的TTL：</p>

<h3>直接在消息上设置</h3>

<pre><code>byte[] messageBodyBytes = "Hello, world!".getBytes();
AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
.expiration("60000")
.build();
channel.basicPublish("my-exchange", "routing-key", properties, messageBodyBytes);
</code></pre>

<h3>为队列设置消息过期TTL</h3>

<p><img src="http://jaskey.github.io/images/rabbitmq/x-message-ttl.png" title="rabbitmq x-message-ttl" alt="rabbitmq x-message-ttl" /></p>

<p>注意，队列还有一个队列TTL，x-expires，这个的意思是队列空置经过一段时间（没有消费者，没有被重新声明，没有人在上面获取消息（basic.get））后，整个队列便会过期删除，不要混淆</p>

<p><strong>如果同时设置了消息的过期和队列消息过期属性，则取两个较小值。</strong></p>

<h2>设计延迟队列：</h2>

<p>例如，我们需要触发一个推送新闻，30分钟后统计这个新闻的下发情况，我们就需要一个延迟队列，新闻推送后，往延迟队列发送一个消息，这个队列的消息在30分钟后被消费，这时候触发即可统计30分钟的下发情况。我们可以这样设计：</p>

<p>定义一个正常的队列： ARRIVAL_STAT，统计程序监听此队列，进行消费。</p>

<p>定义一个“延迟队列”（RabbitMQ没有这样的队列，这里只是人为的制造一个这样的队列）：DELAY_ARRIVAL_STAT，其中设置好对应的x-dead-letter-exchange，x-dead-letter-routing-key。为了简单说明，我使用默认的exchange，那么配置如下：</p>

<pre><code>x-dead-letter-exchange=“”
x-dead-letter-routing-key=“ARRIVAL_STAT”
</code></pre>

<p>意思是，消息当这个队列DELAY_ARRIVAL_STAT的消息变死信之后，就会带着routing key &ldquo;ARRIVAL_STAT&#8221;发送默认的空exchange，即队列ARRIVAL_STAT。</p>

<p>并且这个队列不能有消费者消费消息。</p>

<p>这样我们就实现了消息的死信转发。下一步，只需要让消息在这个DELAY_ARRIVAL_STAT在30分钟后过期变死信即可。按照上文所说，有两种方法，我们可以为队列的消息设置30分钟TTL，或者发送消息的时候指定消息的TTL为30分钟即可。</p>

<p>示例如下：</p>

<p><img src="http://jaskey.github.io/images/rabbitmq/delay-queue-demo.png" title="rabbitmq 延迟队列示意" alt="rabbitmq 延迟队列示意" /></p>

<h2>“延迟队列”的堵塞缺陷</h2>

<p>由于设置了x-dead-letter-exchange的队列本身也是普通队列，其过期的顺序是按照队列头部顺序的过期的。也就是说，如果你队列头的消息A过期时间是5分钟，后面对这个队列发送消息B的带着过期时间1分钟，那么后面的队列B要等队列A过期了才会触发过期：</p>

<blockquote><p>Queues that had a per-message TTL applied to them retroactively (when they already had messages) will discard the messages when specific events occur. Only when expired messages reach the head of a queue will they actually be discarded (or dead-lettered).</p></blockquote>

<p>所以，对于此类多延迟时间的，可以考虑设置多级延迟队列。例如1分钟，5分钟，10分钟，20分钟这样多级的延迟队列，使得延迟相近的尽量放到同一个队列中减少拥堵的最坏情况。</p>

<p><img src="http://jaskey.github.io/images/rabbitmq/multi-delay-queue.png" title="rabbitmq 多级延迟队列" alt="rabbitmq 多级延迟队列" /></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/01/15/rabbitmq-note/">RabbitMQ常用命令与配置</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-01-15T14:56:56+08:00'><span class='date'>2018-01-15 Mon</span> <span class='time'>14:56</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>以下记录RabbitMQ常用的运维命令和配置</p>

<hr />

<h1>常用命令</h1>

<h3>启动进程：</h3>

<pre><code>sbin/rabbitmq-server -detached
</code></pre>

<h3>关闭进程：</h3>

<pre><code>sbin/rabbitmqctl stop
</code></pre>

<h3>创建账号：</h3>

<pre><code>sbin/rabbitmqctl add_user admin ${mq_password}
sbin/rabbitmqctl set_user_tags admin administrator
sbin/rabbitmqctl set_permissions -p '/' admin '.*' '.*' '.*'
</code></pre>

<h3>启动监控：</h3>

<pre><code>#启动监控后，可以用http访问控制台 ip:监控端口（默认原端口+10000）
sbin/rabbitmq-plugins enable rabbitmq_management
</code></pre>

<h3>加入集群：</h3>

<pre><code>#要先停止应用
sbin/rabbitmqctl stop_app
#加入集群，cluster_name为之前启动的那个集群名称，通常为环境变量文件中配置的RABBITMQ_NODE_IP_ADDRESS
sbin/rabbitmqctl join_cluster ${cluster_name}
#再次启动应用    
sbin/rabbitmqctl start_app
</code></pre>

<p>命令文档：<a href="https://www.rabbitmq.com/rabbitmqctl.8.html">https://www.rabbitmq.com/rabbitmqctl.8.html</a></p>

<hr />

<h1>配置文件</h1>

<p>rabbitmq-env.conf</p>

<pre><code>RABBITMQ_NODE_IP_ADDRESS= //IP地址，空串bind所有地址，指定地址bind指定网络接口
RABBITMQ_NODE_PORT=       //TCP端口号，默认是5672
RABBITMQ_NODENAME=        //节点名称。默认是rabbit
RABBITMQ_CONFIG_FILE= //配置文件路径 ，即rabbitmq.config文件路径
RABBITMQ_MNESIA_BASE=     //mnesia所在路径
RABBITMQ_LOG_BASE=        //日志所在路径
RABBITMQ_PLUGINS_DIR=     //插件所在路径
</code></pre>

<p>rabbitmq.config</p>

<pre><code>tcp_listerners    #设置rabbimq的监听端口，默认为[5672]。
disk_free_limit     #磁盘低水位线，若磁盘容量低于指定值则停止接收数据，默认值为{mem_relative, 1.0},即与内存相关联1：1，也可定制为多少byte.
vm_memory_high_watermark    #设置内存低水位线，若低于该水位线，则开启流控机制，默认值是0.4，即内存总量的40%。
hipe_compile     #将部分rabbimq代码用High Performance Erlang compiler编译，可提升性能，该参数是实验性，若出现erlang vm segfaults，应关掉。
force_fine_statistics    #该参数属于rabbimq_management，若为true则进行精细化的统计，但会影响性能。
frame_max     #包大小，若包小则低延迟，若包则高吞吐，默认是131072=128K。
heartbeat     #客户端与服务端心跳间隔，设置为0则关闭心跳，默认是600秒。
</code></pre>

<h1>一台机器启动多个实例</h1>

<p>以上如果希望一个机器中启动多个实例，简单需要配置的地方仅有</p>

<p>rabbitmq-env.conf：</p>

<pre><code>#改个名字
RABBITMQ_NODENAME=your_new_node_name
#改个端口    
RABBITMQ_NODE_PORT=5673
</code></pre>

<p>rabbitmq.config:</p>

<pre><code>%tcp 监听端口对应修改%
{tcp_listeners, [5673]},
</code></pre>

<p>rabbitmq_management下面的监听端口对应修改，建议原端口加10000保持与原来默认的统一</p>

<pre><code>{listener, [{port,     15673}]}
</code></pre>

<p>文档：<a href="http://www.rabbitmq.com/configure.html#configuration-file">http://www.rabbitmq.com/configure.html#configuration-file</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/06/13/rocketmq-client-config/">RocketMQ 客户端配置</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2017-06-13T14:56:56+08:00'><span class='date'>2017-06-13 Tue</span> <span class='time'>14:56</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>RocketMQ的客户端和服务端采取完全不一样的配置机制，客户端没有配置文件，所有的配置选项需要开发者使用对应的配置的setter进行设置。</p>

<p>注： 以下带 * 的，表示为重要参数。</p>

<hr />

<h1>ClientConfig</h1>

<p>RocketMQ的Producer（<code>DefaultMQProducer</code>）和Consumer(<code>DefaultMQPushConsumer</code>，<code>DefaultMQPullConsumer</code>)，甚至运维相关的的admin类（<code>DefaultMQAdminExt</code>）都继承自ClientConfig。这意味着，其中的配置无论Producer还是Consumer都可以进行设置，其中大部分都是公用的配置（但由于设计的问题，有些配置只会对消费或生产生效）。</p>

<h3>namesrvAddr*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>NameServer的地址列表，若是集群，用<code>;</code>作为地址的分隔符。 </td>
<td>-D系统参数<code>rocketmq.namesrv.addr</code>或环境变量<code>NAMESRV_ADDR</code> </td>
</tr>
</tbody>
</table>


<p>无论生产者还是消费者，只要是客户端需要和服务器broker进行操作，就需要依赖Name Server进行服务发现。具体请看：<a href="http://jaskey.github.io/blog/2016/12/14/rocketmq-component/" title="RocketMQ——组件">RocketMQ——组件</a></p>

<h3>instanceName*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>NameServer的地址列表，若是集群，用<code>;</code>作为地址的分隔符。 </td>
<td>从-D系统参数<code>rocketmq.client.name</code>获取，否则就是<code>DEFAULT</code></td>
</tr>
</tbody>
</table>


<p>这个值虽然默认写是<code>DEFAULT</code>，但在启动的时候，如果我们没有显示修改还是维持其<code>DEFAULT</code>的话，RocketMQ会更新为当前的进程号：</p>

<pre><code>public void changeInstanceNameToPID() {
    if (this.instanceName.equals("DEFAULT")) {
        this.instanceName = String.valueOf(UtilAll.getPid());
    }
}
</code></pre>

<p>RocketMQ用一个叫<strong>ClientID</strong>的概念，来唯一标记一个客户端实例，一个客户端实例对于Broker而言会开辟一个Netty的客户端实例。 而ClientID是由ClientIP+InstanceName构成，故如果一个进程中多个实例（无论Producer还是Consumer）ClientIP和InstanceName都一样,他们将公用一个内部实例（同一套网络连接，线程资源等）</p>

<p>此外，此ClientID在对于Consumer负载均衡的时候起到唯一标识的作用，一旦多个实例（无论不同进程、不通机器、还是同一进程）的多个Consumer实例有一样的ClientID，负载均衡的时候必然RocketMQ任然会把两个实例当作一个client（因为同样一个clientID）。 故为了避免不必要的问题，ClientIP+instance Name的组合建议唯一，除非有意需要共用连接、资源。</p>

<h3>clientIP</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>客户端IP</td>
<td><code>RemotingUtil.getLocalAddress()</code> </td>
</tr>
</tbody>
</table>


<p>这个值有两个用处：
1. 对于默认的<code>instanceName</code>（后面说明），如果没有显示设置，会使用ip+进程号，其中的ip便是这里的配置值
2. 对于Producer发送消息的时候，消息本身会存储本值到<code>bornHost</code>，用于标记消息从哪台机器产生的</p>

<h3>clientCallbackExecutorThreads</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>客户端通信层接收到网络请求的时候，处理器的核数</td>
<td><code>Runtime.getRuntime().availableProcessors()</code></td>
</tr>
</tbody>
</table>


<p>虽然大部分指令的发起方是客户端而处理方是broker/NameServer端，但客户端有时候也需要处理远端对发送给自己的命令，最常见的是一些运维指令如<code>GET_CONSUMER_RUNNING_INFO</code>，或者消费实例上线/下线的推送指令<code>NOTIFY_CONSUMER_IDS_CHANGED</code>，这些指令的处理都在一个线程池处理，<code>clientCallbackExecutorThreads</code>控制这个线程池的核数。</p>

<h3>pollNameServerInterval*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>轮询从NameServer获取路由信息的时间间隔</td>
<td>30000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>客户端依靠NameServer做服务发现（具体请看：<a href="http://jaskey.github.io/blog/2016/12/14/rocketmq-component/" title="RocketMQ——组件">RocketMQ——组件</a>），这个间隔决定了新服务上线/下线，客户端最长多久能探测得到。默认是30秒，就是说如果做broker扩容，最长需要30秒客户端才能感知得到新broker的存在。</p>

<h3>heartbeatBrokerInterval*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>定期发送注册心跳到broker的间隔</td>
<td>30000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>客户端依靠心跳告诉broker“我是谁（clientID，ConsumerGroup/ProducerGroup）”，“自己是订阅了什么topic&#8221;，&#8221;要发送什么topic&#8221;。以此，broker会记录并维护这些信息。客户端如果动态更新这些信息，最长则需要这个心跳周期才能告诉broker。</p>

<h3>persistConsumerOffsetInterval*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>作用于Consumer，持久化消费进度的间隔</td>
<td>5000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>RocketMQ采取的是定期批量ack的机制以持久化消费进度。也就是说每次消费消息结束后，并不会立刻ack，而是定期的集中的更新进度。 由于持久化不是立刻持久化的，所以如果消费实例突然退出（如断点）、或者触发了负载均衡分consue queue重排，有可能会有已经消费过的消费进度没有及时更新而导致重新投递。故本配置值越小，重复的概率越低，但同时也会增加网络通信的负担。</p>

<h3>vipChannelEnabled</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>是否启用vip netty通道以发送消息</td>
<td>-D com.rocketmq.sendMessageWithVIPChannel参数的值，若无则是true</td>
</tr>
</tbody>
</table>


<p>broker的netty server会起两个通信服务。两个服务除了服务的端口号不一样，其他都一样。其中一个的端口（配置端口-2）作为vip通道，客户端可以启用本设置项把发送消息此vip通道。</p>

<hr />

<h2>DefaultMQProducer</h2>

<p>所有的消息发送都通过DefaultMQProducer作为入口，以下介绍一下单独属于DefaultMQProducer的一些配置项。</p>

<h3>producerGroup*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>生产组的名称，一类Producer的标识</td>
<td>DEFAULT_PRODUCER</td>
</tr>
</tbody>
</table>


<p>详见 <a href="http://jaskey.github.io/blog/2016/12/15/rocketmq-concept/" title="RocketMQ——角色与术语详解">RocketMQ——角色与术语详解</a></p>

<h3>createTopicKey</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>发送消息的时候，如果没有找到topic，若想自动创建该topic，需要一个key topic，这个值即是key topic的值</td>
<td>TBW102</td>
</tr>
</tbody>
</table>


<p>这是RocketMQ设计非常晦涩的一个概念，整体的逻辑是这样的：</p>

<ul>
<li>生产者正常的发送消息，都是需要topic<strong>预先</strong>创建好的</li>
<li>但是RocketMQ服务端是支持，发送消息的时候，如果topic不存在，在发送的同时自动创建该topic</li>
<li>支持的前提是broker 的配置打开<code>autoCreateTopicEnable=true</code></li>
<li><code>autoCreateTopicEnable=true</code>后，broker会创建一个<code>TBW102</code>的topic，这个就是我们讲的默认的key topic</li>
</ul>


<p>自动构建topic（以下成为T）的过程：</p>

<ol>
<li>Producer发送的时候如果发现该T不存在，就会配置有Producer配置的key topic的那个broker发送消息</li>
<li>broker校验客户端的topic key是否在broker存在，且校验其权限最后一位是否是1（topic权限总共有3位，按位存储，分别是读、写、支持自动创建）</li>
<li>若权限校验通过，先在该broker把T创建，并且权限就是key topic除去最后一位的权限。</li>
</ol>


<p>为了方便理解，以下贴出broker的具体源码并加入部分注释：</p>

<pre><code>                TopicConfig defaultTopicConfig = this.topicConfigTable.get(defaultTopic);//key topic的配置信息
                if (defaultTopicConfig != null) {//key topic 存在
                    if (defaultTopic.equals(MixAll.DEFAULT_TOPIC)) {
                        if (!this.brokerController.getBrokerConfig().isAutoCreateTopicEnable()) {
                            defaultTopicConfig.setPerm(PermName.PERM_READ | PermName.PERM_WRITE);
                        }
                    }

                    if (PermName.isInherited(defaultTopicConfig.getPerm())) {//检验权限，如果允许自动创建
                        topicConfig = new TopicConfig(topic);//创建topic

                        int queueNums =
                            clientDefaultTopicQueueNums &gt; defaultTopicConfig.getWriteQueueNums() ? defaultTopicConfig
                                .getWriteQueueNums() : clientDefaultTopicQueueNums;

                        if (queueNums &lt; 0) {
                            queueNums = 0;
                        }

                        topicConfig.setReadQueueNums(queueNums);
                        topicConfig.setWriteQueueNums(queueNums);
                        int perm = defaultTopicConfig.getPerm();
                        perm &amp;= ~PermName.PERM_INHERIT;//权限按照key topic的来
                        topicConfig.setPerm(perm);
                        topicConfig.setTopicSysFlag(topicSysFlag);
                        topicConfig.setTopicFilterType(defaultTopicConfig.getTopicFilterType());
                    } else {//权限校验不过，自动创建失败
                        LOG.warn("Create new topic failed, because the default topic[{}] has no perm [{}] producer:[{}]",
                                defaultTopic, defaultTopicConfig.getPerm(), remoteAddress);
                    }
                } else {//key topic不存在，创建失败
                    LOG.warn("Create new topic failed, because the default topic[{}] not exist. producer:[{}]", defaultTopic, remoteAddress);
                }

             ...//把创建的topic维护起来
</code></pre>

<p>总的来说，这个功能设计出来比较晦涩，而从运维的角度上看，topic在大部分场景下也应该预创建，故本特性没有必要的话，也不会用到，这个配置也没有必要特殊的设置。</p>

<p>关于这个TBW102非常不直观的问题，我已经提了issue ：<a href="https://issues.apache.org/jira/browse/ROCKETMQ-223">https://issues.apache.org/jira/browse/ROCKETMQ-223</a></p>

<h3>defaultTopicQueueNums</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>自动创建topic的话，默认queue数量是多少</td>
<td>4</td>
</tr>
</tbody>
</table>


<h3>sendMsgTimeout</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>默认的发送超时时间</td>
<td>3000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>若发送的时候不显示指定timeout，则使用此设置的值作为超时时间。</p>

<p>对于异步发送，超时后会进入回调的<code>onException</code>，对于同步发送，超时则会得到一个<code>RemotingTimeoutException</code>。</p>

<h3>compressMsgBodyOverHowmuch</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消息body需要压缩的阈值</td>
<td>1024 * 4，4K</td>
</tr>
</tbody>
</table>


<h3>retryTimesWhenSendFailed</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>同步发送失败的话，rocketmq内部重试多少次</td>
<td>2</td>
</tr>
</tbody>
</table>


<h3>retryTimesWhenSendAsyncFailed</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>异步发送失败的话，rocketmq内部重试多少次</td>
<td>2</td>
</tr>
</tbody>
</table>


<h3>retryAnotherBrokerWhenNotStoreOK</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>发送的结果如果不是SEND_OK状态，是否当作失败处理而尝试重发</td>
<td>false</td>
</tr>
</tbody>
</table>


<p>发送结果总共有4钟：</p>

<pre><code>SEND_OK, //状态成功，无论同步还是存储
FLUSH_DISK_TIMEOUT, // broker刷盘策略为同步刷盘（SYNC_FLUSH）的话时候，等待刷盘的时候超时
FLUSH_SLAVE_TIMEOUT, // master role采取同步复制策略（SYNC_MASTER）的时候，消息尝试同步到slave超时
SLAVE_NOT_AVAILABLE, //slave不可用
</code></pre>

<p>注：从源码上看，此配置项只对同步发送有效，异步、oneway（由于无法获取结果，肯定无效）均无效</p>

<h3>retryAnotherBrokerWhenNotStoreOK</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>客户端验证，允许发送的最大消息体大小</td>
<td>1024 * 1024 * 4，4M</td>
</tr>
</tbody>
</table>


<p>若超过此大小，会得到一个响应码13（MESSAGE_ILLEGAL）的<code>MQClientException</code>异常</p>

<hr />

<h2>TransactionMQProducer</h2>

<p>事务生产者，截至至4.1，由于暂时事务回查功能缺失，整体并不完全可用，配置暂时忽略，等后面功能完善后补上。</p>

<p><a href="https://issues.apache.org/jira/browse/ROCKETMQ-123">https://issues.apache.org/jira/browse/ROCKETMQ-123</a></p>

<hr />

<h2>DefaultMQPushConsumer</h2>

<p>最常用的消费者，使用push模式（长轮询），封装了各种拉取的方法和返回结果的判断。下面介绍其配置。</p>

<h3>consumerGroup*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费组的名称，用于标识一类消费者</td>
<td>无默认值，必设</td>
</tr>
</tbody>
</table>


<p>详见 <a href="http://jaskey.github.io/blog/2016/12/15/rocketmq-concept/" title="RocketMQ——角色与术语详解">RocketMQ——角色与术语详解</a></p>

<h3>messageModel*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费模式</td>
<td>MessageModel.CLUSTERING</td>
</tr>
</tbody>
</table>


<p>可选值有两个：</p>

<ol>
<li>CLUSTERING //集群消费模式</li>
<li>BROADCASTING //广播消费模式</li>
</ol>


<p>两种模式的区别详见：<a href="http://jaskey.github.io/blog/2016/12/15/rocketmq-concept/" title="RocketMQ——角色与术语详解">RocketMQ——角色与术语详解</a></p>

<h3>consumeFromWhere*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费点策略</td>
<td>ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET</td>
</tr>
</tbody>
</table>


<p>可选值有两个：</p>

<ol>
<li>CONSUME_FROM_LAST_OFFSET //队列尾消费</li>
<li>CONSUME_FROM_FIRST_OFFSET //队列头消费</li>
<li>CONSUME_FROM_TIMESTAMP //按照日期选择某个位置消费</li>
</ol>


<p>注：此策略只生效于新在线测consumer group，如果是老的已存在的consumer group，都降按照已经持久化的consume offset进行消费</p>

<p>具体说明祥见： <a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management/" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a></p>

<h3>consumeTimestamp:</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>CONSUME_FROM_LAST_OFFSET的时候使用，从哪个时间点开始消费</td>
<td>半小时前</td>
</tr>
</tbody>
</table>


<p>格式为yyyyMMddhhmmss 如 20131223171201</p>

<h3>allocateMessageQueueStrategy*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>负载均衡策略算法</td>
<td>AllocateMessageQueueAveragely（取模平均分配）</td>
</tr>
</tbody>
</table>


<p>这个算法可以自行扩展以使用自定义的算法，目前有以下算法可以使用</p>

<ul>
<li>AllocateMessageQueueAveragely  //取模平均</li>
<li>AllocateMessageQueueAveragelyByCircle //环形平均</li>
<li>AllocateMessageQueueByConfig // 按照配置，传入听死的messageQueueList</li>
<li>AllocateMessageQueueByMachineRoom //按机房，从源码上看，必须和阿里的某些broker命名一致才行</li>
<li>AllocateMessageQueueConsistentHash //一致性哈希算法，本人于4.1提交的特性。用于解决“惊群效应”。</li>
</ul>


<p>需要自行扩展的算法的，需要实现<code>org.apache.rocketmq.client.consumer.rebalance.AllocateMessageQueueStrategy</code></p>

<p>具体分配consume queue的过程祥见： <a href="http://jaskey.github.io/blog/2016/12/19/rocketmq-rebalance/" title="RocketMQ——水平扩展及负载均衡详解">RocketMQ——水平扩展及负载均衡详解</a></p>

<h3>subscription</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>订阅关系（topic->sub expression）</td>
<td>{}</td>
</tr>
</tbody>
</table>


<p>不建议设置，订阅topic建议直接调用<code>subscribe</code>接口</p>

<h3>messageListener</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消息处理监听器（回调）</td>
<td>null</td>
</tr>
</tbody>
</table>


<p>不建议设置，注册监听的时候应调用<code>registerMessageListener</code></p>

<h3>offsetStore</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消息消费进度存储器 </td>
<td>null</td>
</tr>
</tbody>
</table>


<p>不建议设置，<code>offsetStore</code> 有两个策略：<code>LocalFileOffsetStore</code> 和 <code>RemoteBrokerOffsetStore</code>。</p>

<p>若没有显示设置的情况下，广播模式将使用<code>LocalFileOffsetStore</code>，集群模式将使用<code>RemoteBrokerOffsetStore</code>，不建议修改。</p>

<h3>consumeThreadMin*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费线程池的core size</td>
<td>20</td>
</tr>
</tbody>
</table>


<p>PushConsumer会内置一个消费线程池，这个配置控制此线程池的core size</p>

<h3>consumeThreadMax*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费线程池的max size</td>
<td>64</td>
</tr>
</tbody>
</table>


<p>PushConsumer会内置一个消费线程池，这个配置控制此线程池的max size</p>

<h3>adjustThreadPoolNumsThreshold</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>动态扩线程核数的消费堆积阈值</td>
<td>1000</td>
</tr>
</tbody>
</table>


<p>相关功能以废弃，不建议设置</p>

<h3>consumeConcurrentlyMaxSpan</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>并发消费下，单条consume queue队列允许的最大offset跨度，达到则触发流控</td>
<td>2000</td>
</tr>
</tbody>
</table>


<p>注：只对并发消费（<code>ConsumeMessageConcurrentlyService</code>）生效</p>

<p>更多分析祥见： <a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management/" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a></p>

<h3>pullThresholdForQueue</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>consume queue流控的阈值</td>
<td>1000</td>
</tr>
</tbody>
</table>


<p>每条consume queue的消息拉取下来后会缓存到本地，消费结束会删除。当累积达到一个阈值后，会触发该consume queue的流控。</p>

<p>更多分析祥见： <a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management/" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a></p>

<p>截至到4.1，流控级别只能针对consume queue级别，针对topic级别的流控已经提了issue: <a href="https://issues.apache.org/jira/browse/ROCKETMQ-106">https://issues.apache.org/jira/browse/ROCKETMQ-106</a></p>

<h3>pullInterval*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>拉取的间隔</td>
<td>0，单位毫秒</td>
</tr>
</tbody>
</table>


<p>由于RocketMQ采取的pull的方式进行消息投递，每此会发起一个异步pull请求，得到请求后会再发起下次请求，这个间隔默认是0，表示立刻再发起。在间隔为0的场景下，消息投递的及时性几乎等同用Push实现的机制。</p>

<h3>pullBatchSize*</h3>

<p>f
| 配置说明 | 默认值 |
| &mdash;&mdash;| &mdash;&mdash; |
|一次最大拉取的批量大小|32|</p>

<p>每次发起pull请求到broker，客户端需要指定一个最大batch size，表示这次拉取消息最多批量拉取多少条。</p>

<h3>consumeMessageBatchMaxSize</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>批量消费的最大消息条数</td>
<td>1</td>
</tr>
</tbody>
</table>


<p>你可能发现了，RocketMQ的注册监听器回调的回调方法签名是类似这样的：</p>

<pre><code>ConsumeConcurrentlyStatus consumeMessage(final List&lt;MessageExt&gt; msgs, final ConsumeConcurrentlyContext context);
</code></pre>

<p>里面的消息是一个集合List而不是单独的msg，这个<code>consumeMessageBatchMaxSize</code>就是控制这个集合的最大大小。</p>

<p>而由于拉取到的一批消息会立刻拆分成N（取决于consumeMessageBatchMaxSize）批消费任务，所以集合中msgs的最大大小是<code>consumeMessageBatchMaxSize</code>和<code>pullBatchSize</code>的较小值。</p>

<h3>postSubscriptionWhenPull</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>每次拉取的时候是否更新订阅关系</td>
<td>false</td>
</tr>
</tbody>
</table>


<p>从源码上看，这个值若是true,且不是class fliter模式，则每次拉取的时候会把subExpression带上到pull的指令中，broker发现这个指令会根据这个上传的表达式重新build出注册数据，而不是直接使用读取的缓存数据。</p>

<h3>maxReconsumeTimes</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>一个消息如果消费失败的话，最多重新消费多少次才投递到死信队列</td>
<td>-1</td>
</tr>
</tbody>
</table>


<p>注，这个值默认值虽然是-1，但是实际使用的时候默认并不是-1。按照消费是并行还是串行消费有所不同的默认值。</p>

<p>并行：默认16次</p>

<p>串行：默认无限大（Interge.MAX_VALUE）。由于顺序消费的特性必须等待前面的消息成功消费才能消费后面的，默认无限大即一直不断消费直到消费完成。</p>

<h3>suspendCurrentQueueTimeMillis</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>串行消费使用，如果返回<code>ROLLBACK</code>或者<code>SUSPEND_CURRENT_QUEUE_A_MOMENT</code>，再次消费的时间间隔</td>
<td>1000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>注：如果消费回调中对<code>ConsumeOrderlyContext</code>中的<code>suspendCurrentQueueTimeMillis</code>进行过设置，则使用用户设置的值作为消费间隔。</p>

<h3>consumeTimeout</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费的最长超时时间</td>
<td>15，<strong> 单位分钟 </strong></td>
</tr>
</tbody>
</table>


<p>如果消费超时，RocketMQ会等同于消费失败来处理，更多分析祥见： <a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management/" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a></p>

<hr />

<h2>DefaultMQPullConsumer</h2>

<p>采取主动调用Pull接口的模式的消费者，主动权更大，但是使用难度也相对更大。以下介绍其配置，部分配置和PushConsumer一致。</p>

<h3>consumerGroup*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费组的名称，用于标识一类消费者</td>
<td>无默认值，必设</td>
</tr>
</tbody>
</table>


<p>详见 <a href="http://jaskey.github.io/blog/2016/12/15/rocketmq-concept/" title="RocketMQ——角色与术语详解">RocketMQ——角色与术语详解</a></p>

<h3>registerTopics*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费者需要监听的topic</td>
<td>空集合</td>
</tr>
</tbody>
</table>


<p>由于没有subscribe接口，用户需要自己把想要监听的topic设置到此集合中，RocketMQ内部会依靠此来发送对应心跳数据。</p>

<h3>messageModel*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消费模式</td>
<td>MessageModel.CLUSTERING</td>
</tr>
</tbody>
</table>


<p>可选值有两个：</p>

<ol>
<li>CLUSTERING //集群消费模式</li>
<li>BROADCASTING //广播消费模式</li>
</ol>


<p>两种模式的区别详见：<a href="http://jaskey.github.io/blog/2016/12/15/rocketmq-concept/" title="RocketMQ——角色与术语详解">RocketMQ——角色与术语详解</a></p>

<h3>allocateMessageQueueStrategy*</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>负载均衡策略算法</td>
<td>AllocateMessageQueueAveragely（取模平均分配）</td>
</tr>
</tbody>
</table>


<p>见DefaultPushConsumer的说明</p>

<h3>offsetStore</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>消息消费进度存储器 </td>
<td>null</td>
</tr>
</tbody>
</table>


<p>不建议设置，<code>offsetStore</code> 有两个策略：<code>LocalFileOffsetStore</code> 和 <code>RemoteBrokerOffsetStore</code>。</p>

<p>若没有显示设置的情况下，广播模式将使用<code>LocalFileOffsetStore</code>，集群模式将使用<code>RemoteBrokerOffsetStore</code>，不建议修改。</p>

<h3>maxReconsumeTimes</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>调用<code>sendMessageBack</code>的时候，如果发现重新消费超过这个配置的值，则投递到死信队列</td>
<td>16</td>
</tr>
</tbody>
</table>


<p>由于PullConsumer没有管理消费的线程池和管理器，需要用户自己处理各种消费结果和拉取结果，故需要投递到重试队列或死信队列的时候需要显示调用<code>sendMessageBack</code>。</p>

<p>回传消息的时候会带上maxReconsumeTimes的值，broker发现此消息已经消费超过此值，则投递到死信队列，否则投递到重试队列。此逻辑和<code>DefaultPushConsumer</code>是一致的，只是PushConsumer无需用户显示调用。</p>

<h3>brokerSuspendMaxTimeMillis</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>broker在长轮询下，连接最长挂起的时间</td>
<td>20*1000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>长轮询具体逻辑不在本文论述，且RocketMQ不建议修改此值。</p>

<h3>consumerTimeoutMillisWhenSuspend</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>broker在长轮询下，客户端等待broker响应的最长等待超时时间</td>
<td>30*1000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>长轮询具体逻辑不在本文论述，且RocketMQ不建议修改此值，此值一定要大于<code>brokerSuspendMaxTimeMillis</code></p>

<h3>consumerPullTimeoutMillis</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>pull的socket 超时时间</td>
<td>10*1000，单位毫秒</td>
</tr>
</tbody>
</table>


<p>虽然注释上说是socket超时时间，但是从源码上看，此值的设计是不启动长轮询也不指定timeout的情况下，拉取的超时时间。</p>

<h3>messageQueueListener</h3>

<table>
<thead>
<tr>
<th> 配置说明 </th>
<th> 默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>负载均衡consume queue分配变化的通知监听器</td>
<td>null</td>
</tr>
</tbody>
</table>


<p>由于pull操作需要用户自己去触发，故如果负载均衡发生变化，要有方法告知用户现在分到的新consume queue是什么。使用方可以实现此接口以达到此目的：</p>

<pre><code>/**
 * A MessageQueueListener is implemented by the application and may be specified when a message queue changed
 */
public interface MessageQueueListener {
/**
 * @param topic message topic
 * @param mqAll all queues in this message topic
 * @param mqDivided collection of queues,assigned to the current consumer
 */
void messageQueueChanged(final String topic, final Set&lt;MessageQueue&gt; mqAll,final Set&lt;MessageQueue&gt; mqDivided);
}
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/02/16/rocketmq-clean-commitlog/">RocketMQ——消息文件过期原理</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2017-02-16T11:49:23+08:00'><span class='date'>2017-02-16 Thu</span> <span class='time'>11:49</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management//" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a> 文中提过，所有的消费均是客户端发起Pull请求的，告诉消息的offset位置，broker去查询并返回。但是有一点需要非常明确的是，消息消费后，消息其实<strong>并没有</strong>物理地被清除，这是一个非常特殊的设计。本文来探索此设计的一些细节。</p>

<h2>消费完后的消息去哪里了？</h2>

<p>消息的存储是一直存在于CommitLog中的。而由于CommitLog是以文件为单位（而非消息）存在的，CommitLog的设计是只允许顺序写的，且每个消息大小不定长，所以这决定了消息文件几乎不可能按照消息为单位删除（否则性能会极具下降，逻辑也非常复杂）。所以消息被消费了，消息所占据的物理空间并不会立刻被回收。</p>

<p>但消息既然一直没有删除，那RocketMQ怎么知道应该投递过的消息就不再投递？——答案是客户端自身维护——客户端拉取完消息之后，在响应体中，broker会返回下一次应该拉取的位置，PushConsumer通过这一个位置，更新自己下一次的pull请求。这样就保证了正常情况下，消息只会被投递一次。</p>

<h2>什么时候清理物理消息文件？</h2>

<p>那消息文件到底删不删，什么时候删？</p>

<p>消息存储在CommitLog之后，的确是会被清理的，但是这个清理只会在以下任一条件成立才会批量删除消息文件（CommitLog）：</p>

<ol>
<li>消息文件过期（默认72小时），且到达清理时点（默认是凌晨4点），删除过期文件。</li>
<li>消息文件过期（默认72小时），且磁盘空间达到了水位线（默认75%），删除过期文件。</li>
<li>磁盘已经达到必须释放的上限（85%水位线）的时候，则开始批量清理文件（无论是否过期），直到空间充足。</li>
</ol>


<p>注：若磁盘空间达到危险水位线（默认90%），出于保护自身的目的，broker会拒绝写入服务。</p>

<h2>这样设计带来的好处</h2>

<p>消息的物理文件一直存在，消费逻辑只是听客户端的决定而搜索出对应消息进行，这样做，笔者认为，有以下几个好处：</p>

<ol>
<li><p>一个消息很可能需要被N个消费组（设计上很可能就是系统）消费，但消息只需要存储一份，消费进度单独记录即可。这给强大的消息堆积能力提供了很好的支持——一个消息无需复制N份，就可服务N个消费组。</p></li>
<li><p>由于消费从哪里消费的决定权一直都是客户端决定，所以只要消息还在，就可以消费到，这使得RocketMQ可以支持其他传统消息中间件不支持的回溯消费。即我可以通过设置消费进度回溯，就可以让我的消费组重新像放快照一样消费历史消息；或者我需要另一个系统也复制历史的数据，只需要另起一个消费组从头消费即可（前提是消息文件还存在）。</p></li>
<li><p>消息索引服务。只要消息还存在就能被搜索出来。所以可以依靠消息的索引搜索出消息的各种原信息，方便事后排查问题。</p></li>
</ol>


<p>注：在消息清理的时候，由于消息文件默认是1GB，所以在清理的时候其实是在删除一个大文件操作，这对于IO的压力是非常大的，这时候如果有消息写入，写入的耗时会明显变高。这个现象可以在凌晨4点（默认删时间时点）后的附近观察得到。</p>

<p>RocketMQ官方建议Linux下文件系统改为Ext4，对于文件删除操作相比Ext3有非常明显的提升。</p>

<h2>跳过历史消息的处理</h2>

<p>由于消息本身是没有过期的概念，只有文件才有过期的概念。那么对于很多业务场景——一个消息如果太老，是无需要被消费的，是不合适的。</p>

<p>这种需要跳过历史消息的场景，在RocketMQ要怎么实现呢？</p>

<p>对于一个全新的消费组，PushConsumer默认就是跳过以前的消息而从最尾开始消费的，解析请参看<a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management//" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a>相关章节。</p>

<p>但对于已存在的消费组，RocketMQ没有内置的跳过历史消息的实现，但有以下手段可以解决：</p>

<ol>
<li><p>自身的消费代码按照日期过滤，太老的消息直接过滤。如：</p>

<pre><code>     @Override
     public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) {
         for(MessageExt msg: msgs){
             if(System.currentTimeMillis()-msg.getBornTimestamp()&gt;60*1000) {//一分钟之前的认为过期
                 continue;//过期消息跳过
             }

             //do consume here

         }
         return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
     }
</code></pre></li>
<li><p>自身的消费代码代码判断消息的offset和MAX_OFFSET相差很远，认为是积压了很多，直接return CONSUME_SUCCESS过滤。</p>

<pre><code>     @Override
     public ConsumeConcurrentlyStatus consumeMessage(//
         List&lt;MessageExt&gt; msgs, //
         ConsumeConcurrentlyContext context) {
         long offset = msgs.get(0).getQueueOffset();
         String maxOffset = msgs.get(0).getProperty(MessageConst.PROPERTY_MAX_OFFSET);
         long diff = Long. parseLong(maxOffset) - offset;
         if (diff &gt; 100000) { //消息堆积了10W情况的特殊处理
             return ConsumeConcurrentlyStatus. CONSUME_SUCCESS;
         }
         //do consume here
         return ConsumeConcurrentlyStatus. CONSUME_SUCCESS;
     }
</code></pre></li>
<li><p>消费者启动前，先调整该消费组的消费进度，再开始消费。可以人工使用控制台命令resetOffsetByTime把消费进度调整到后面，再启动消费。</p></li>
<li>原理同3，但使用代码来控制。代码中调用内部的运维接口，具体代码实例祥见<code>ResetOffsetByTimeCommand.java</code>.</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/25/rocketmq-consume-offset-management/">RocketMQ——消息ACK机制及消费进度管理</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2017-01-25T20:49:23+08:00'><span class='date'>2017-01-25 Wed</span> <span class='time'>20:49</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://jaskey.github.io/blog/2016/12/19/rocketmq-rebalance/" title="RokectMQ——水平扩展及负载均衡详解">RokectMQ——水平扩展及负载均衡详解</a> 中剖析过，consumer的每个实例是靠队列分配来决定如何消费消息的。那么消费进度具体是如何管理的，又是如何保证消息成功消费的?（RocketMQ有保证消息肯定消费成功的特性,失败则重试）？</p>

<p>本文将详细解析消息具体是如何ack的，又是如何保证消费肯定成功的。</p>

<p>由于以上工作所有的机制都实现在PushConsumer中，所以本文的原理均只适用于RocketMQ中的PushConsumer即Java客户端中的<code>DefaultPushConsumer</code>。 若使用了PullConsumer模式，类似的工作如何ack，如何保证消费等均需要使用方自己实现。</p>

<p>注：广播消费和集群消费的处理有部分区别，以下均特指集群消费（CLSUTER），广播（BROADCASTING）下部分可能不适用。</p>

<h2>保证消费成功</h2>

<p>PushConsumer为了保证消息肯定消费成功，只有使用方明确表示消费成功，RocketMQ才会认为消息消费成功。中途断电，抛出异常等都不会认为成功——即都会重新投递。</p>

<p>消费的时候，我们需要注入一个消费回调，具体sample代码如下：</p>

<pre><code>    consumer.registerMessageListener(new MessageListenerConcurrently() {
        @Override
        public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) {
            System.out.println(Thread.currentThread().getName() + " Receive New Messages: " + msgs);
            doMyJob();//执行真正消费
            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
        }
    });
</code></pre>

<p>业务实现消费回调的时候，当且仅当此回调函数返回<code>ConsumeConcurrentlyStatus.CONSUME_SUCCESS</code>，RocketMQ才会认为这批消息（默认是1条）是消费完成的。（具体如何ACK见后面章节）</p>

<p>如果这时候消息消费失败，例如数据库异常，余额不足扣款失败等一切业务认为消息需要重试的场景，只要返回<code>ConsumeConcurrentlyStatus.RECONSUME_LATER</code>，RocketMQ就会认为这批消息消费失败了。</p>

<p>为了保证消息是肯定被至少消费成功一次，RocketMQ会把这批消息重发回Broker（topic不是原topic而是这个消费租的RETRY topic），在延迟的某个时间点（默认是10秒，业务可设置）后，再次投递到这个ConsumerGroup。而如果一直这样重复消费都持续失败到一定次数（默认16次），就会投递到DLQ死信队列。应用可以监控死信队列来做人工干预。</p>

<p>注：</p>

<ol>
<li>如果业务的回调没有处理好而抛出异常，会认为是消费失败当<code>ConsumeConcurrentlyStatus.RECONSUME_LATER</code>处理。</li>
<li>当使用顺序消费的回调<code>MessageListenerOrderly</code>时，由于顺序消费是要前者消费成功才能继续消费，所以没有<code>RECONSUME_LATER</code>的这个状态，只有<code>SUSPEND_CURRENT_QUEUE_A_MOMENT</code>来暂停队列的其余消费，直到原消息不断重试成功为止才能继续消费。</li>
</ol>


<h2>启动的时候从哪里消费</h2>

<p>当新实例启动的时候，PushConsumer会拿到本消费组broker已经记录好的消费进度（consumer offset），按照这个进度发起自己的第一次Pull请求。</p>

<p>如果这个消费进度在Broker并没有存储起来，证明这个是一个全新的消费组，这时候客户端有几个策略可以选择：</p>

<pre><code>CONSUME_FROM_LAST_OFFSET //默认策略，从该队列最尾开始消费，即跳过历史消息
CONSUME_FROM_FIRST_OFFSET //从队列最开始开始消费，即历史消息（还储存在broker的）全部消费一遍
CONSUME_FROM_TIMESTAMP//从某个时间点开始消费，和setConsumeTimestamp()配合使用，默认是半个小时以前
</code></pre>

<p>所以，社区中经常有人问：“为什么我设了<code>CONSUME_FROM_LAST_OFFSET</code>，历史的消息还是被消费了”？ 原因就在于只有全新的消费组才会使用到这些策略，老的消费组都是按已经存储过的消费进度继续消费。</p>

<p>对于老消费组想跳过历史消息需要自身做过滤，或者使用先修改消费进度。示例代码请参看：<a href="http://jaskey.github.io/blog/2017/02/16/rocketmq-clean-commitlog/" title="RocketMQ——消息文件过期原理">RocketMQ——消息文件过期原理</a></p>

<h2>消息ACK机制</h2>

<p>RocketMQ是以consumer group+queue为单位是管理消费进度的，以一个consumer offset标记这个这个消费组在这条queue上的消费进度。</p>

<p>如果某已存在的消费组出现了新消费实例的时候，依靠这个组的消费进度，就可以判断第一次是从哪里开始拉取的。</p>

<p>每次消息成功后，本地的消费进度会被更新，然后由定时器定时同步到broker，以此持久化消费进度。</p>

<p>但是每次记录消费进度的时候，只会把一批消息中最小的offset值为消费进度值，如下图：</p>

<p><img src="/images/rocketmq/rocketmq-ack.png" title="message ack" alt="message ack" /></p>

<p>这钟方式和传统的一条message单独ack的方式有本质的区别。性能上提升的同时，会带来一个潜在的重复问题——由于消费进度只是记录了一个下标，就可能出现拉取了100条消息如 2101-2200的消息，后面99条都消费结束了，只有2101消费一直没有结束的情况。</p>

<p>在这种情况下，RocketMQ为了保证消息肯定被消费成功，消费进度职能维持在2101，直到2101也消费结束了，本地的消费进度才能标记2200消费结束了（注：consumerOffset=2201）。</p>

<p>在这种设计下，就有消费大量重复的风险。如2101在还没有消费完成的时候消费实例突然退出（机器断电，或者被kill）。这条queue的消费进度还是维持在2101，当queue重新分配给新的实例的时候，新的实例从broker上拿到的消费进度还是维持在2101，这时候就会又从2101开始消费，2102-2200这批消息实际上已经被消费过还是会投递一次。</p>

<p>对于这个场景，RocketMQ暂时无能为力，所以业务必须要保证消息消费的幂等性，这也是RocketMQ官方多次强调的态度。</p>

<p>实际上，从源码的角度上看，RocketMQ可能是考虑过这个问题的，截止到3.2.6的版本的源码中，可以看到为了缓解这个问题的影响面，<code>DefaultMQPushConsumer</code>中有个配置<code>consumeConcurrentlyMaxSpan</code></p>

<pre><code>/**
 * Concurrently max span offset.it has no effect on sequential consumption
 */
private int consumeConcurrentlyMaxSpan = 2000;
</code></pre>

<p>这个值默认是2000，当RocketMQ发现本地缓存的消息的最大值-最小值差距大于这个值（2000）的时候，会触发流控——也就是说如果头尾都卡住了部分消息，达到了这个阈值就不再拉取消息。</p>

<p>但作用实际很有限，像刚刚这个例子，2101的消费是死循环，其他消费非常正常的话，是无能为力的。一旦退出，在不人工干预的情况下，2101后所有消息全部重复!</p>

<h3>Ack卡进度解决方案</h3>

<p>实际上对于卡住进度的场景，可以选择弃车保帅的方案：把消息卡住那些消息，先ack掉，让进度前移。但要保证这条消息不会因此丢失，ack之前要把消息sendBack回去，这样这条卡住的消息就会必然重复，但会解决潜在的大量重复的场景。 这也是我们公司<strong>自己定制</strong>的解决方案。</p>

<p>   部分源码如下：</p>

<pre><code>class ConsumeRequestWithUnAck implements Runnable {
    final ConsumeRequest consumeRequest;
    final long resendAfterIfStillUnAck;//n毫秒没有消费完，就重发

    ConsumeRequestWithUnAck(ConsumeRequest consumeRequest,long resendAfterIfStillUnAck) {
        this.consumeRequest = consumeRequest;
        this.resendAfterIfStillUnAck = resendAfterIfStillUnAck;
    }

    @Override
    public void run() {
        //每次消费前，计划延时任务，超时则ack并重发
        final WeakReference&lt;ConsumeRequest&gt; crReff = new WeakReference&lt;&gt;(this.consumeRequest);
        ScheduledFuture scheduledFuture=null;
        if(!ConsumeDispatcher.this.ackAndResendScheduler.isShutdown()) {
            scheduledFuture= ConsumeDispatcher.this.ackAndResendScheduler.schedule(new ConsumeTooLongChecker(crReff),resendAfterIfStillUnAck,TimeUnit.MILLISECONDS);
        }
        try{
            this.consumeRequest.run();//正常执行并更新offset
        }
        finally {
            if (scheduledFuture != null) scheduledFuture.cancel(false);//消费结束后,取消任务
        }
    }

}
</code></pre>

<ol>
<li>定义了一个装饰器，把原来的ConsumeRequest对象包了一层。</li>
<li>装饰器中，每条消息消费前都会调度一个调度器，定时触发，触发的时候如果发现消息还存在，就执行sendback并ack的操作。</li>
</ol>


<p>后来RocketMQ显然也发现了这个问题，RocketMQ在3.5.8之后也是采用这样的方案去解决这个问题。只是实现方式上有所不同（事实上我认为RocketMQ的方案还不够完善）</p>

<ol>
<li>在pushConsumer中 有一个<code>consumeTimeout</code>字段（默认15分钟），用于设置最大的消费超时时间。消费前会记录一个消费的开始时间，后面用于比对。</li>
<li>消费者启动的时候，会定期扫描所有消费的消息，达到这个timeout的那些消息，就会触发sendBack并ack的操作。这里扫描的间隔也是consumeTimeout（单位分钟）的间隔。</li>
</ol>


<p>核心源码如下：</p>

<pre><code>//ConsumeMessageConcurrentlyService.java
public void start() {
    this.CleanExpireMsgExecutors.scheduleAtFixedRate(new Runnable() {

        @Override
        public void run() {
            cleanExpireMsg();
        }

    }, this.defaultMQPushConsumer.getConsumeTimeout(), this.defaultMQPushConsumer.getConsumeTimeout(), TimeUnit.MINUTES);
}
//ConsumeMessageConcurrentlyService.java
private void cleanExpireMsg() {
    Iterator&lt;Map.Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it =
            this.defaultMQPushConsumerImpl.getRebalanceImpl().getProcessQueueTable().entrySet().iterator();
    while (it.hasNext()) {
        Map.Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next();
        ProcessQueue pq = next.getValue();
        pq.cleanExpiredMsg(this.defaultMQPushConsumer);
    }
}

//ProcessQueue.java
public void cleanExpiredMsg(DefaultMQPushConsumer pushConsumer) {
    if (pushConsumer.getDefaultMQPushConsumerImpl().isConsumeOrderly()) {
        return;
    }

    int loop = msgTreeMap.size() &lt; 16 ? msgTreeMap.size() : 16;
    for (int i = 0; i &lt; loop; i++) {
        MessageExt msg = null;
        try {
            this.lockTreeMap.readLock().lockInterruptibly();
            try {
                if (!msgTreeMap.isEmpty() &amp;&amp; System.currentTimeMillis() - Long.parseLong(MessageAccessor.getConsumeStartTimeStamp(msgTreeMap.firstEntry().getValue())) &gt; pushConsumer.getConsumeTimeout() * 60 * 1000) {
                    msg = msgTreeMap.firstEntry().getValue();
                } else {

                    break;
                }
            } finally {
                this.lockTreeMap.readLock().unlock();
            }
        } catch (InterruptedException e) {
            log.error("getExpiredMsg exception", e);
        }

        try {

            pushConsumer.sendMessageBack(msg, 3);
            log.info("send expire msg back. topic={}, msgId={}, storeHost={}, queueId={}, queueOffset={}", msg.getTopic(), msg.getMsgId(), msg.getStoreHost(), msg.getQueueId(), msg.getQueueOffset());
            try {
                this.lockTreeMap.writeLock().lockInterruptibly();
                try {
                    if (!msgTreeMap.isEmpty() &amp;&amp; msg.getQueueOffset() == msgTreeMap.firstKey()) {
                        try {
                            msgTreeMap.remove(msgTreeMap.firstKey());
                        } catch (Exception e) {
                            log.error("send expired msg exception", e);
                        }
                    }
                } finally {
                    this.lockTreeMap.writeLock().unlock();
                }
            } catch (InterruptedException e) {
                log.error("getExpiredMsg exception", e);
            }
        } catch (Exception e) {
            log.error("send expired msg exception", e);
        }
    }
}
</code></pre>

<p>通过这个逻辑对比我定制的时间，可以看出有几个不太完善的问题：</p>

<ol>
<li>消费timeout的时间非常不精确。由于扫描的间隔是15分钟，所以实际上触发的时候，消息是有可能卡住了接近30分钟（15*2）才被清理。</li>
<li>由于定时器一启动就开始调度了，中途这个consumeTimeout再更新也不会生效。</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/12/19/rocketmq-rebalance/">RocketMQ——水平扩展及负载均衡详解</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-12-19T20:49:23+08:00'><span class='date'>2016-12-19 Mon</span> <span class='time'>20:49</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>RocketMQ是一个分布式具有高度可扩展性的消息中间件。本文旨在探索在broker端，生产端，以及消费端是如何做到横向扩展以及负载均衡的。</p>

<h2>Broker端水平扩展</h2>

<h3>Broker负载均衡</h3>

<p>Broker是以group为单位提供服务。一个group里面分master和slave,master和slave存储的数据一样，slave从master同步数据（同步双写或异步复制看配置）。</p>

<p>通过nameserver暴露给客户端后，只是客户端关心（注册或发送）一个个的topic路由信息。路由信息中会细化为message queue的路由信息。而message queue会分布在不同的broker group。所以对于客户端来说，分布在不同broker group的message queue为成为一个服务集群，但客户端会把请求分摊到不同的queue。</p>

<p>而由于压力分摊到了不同的queue,不同的queue实际上分布在不同的Broker group，也就是说压力会分摊到不同的broker进程，这样消息的存储和转发均起到了负载均衡的作用。</p>

<p>Broker一旦需要横向扩展，只需要增加broker group，然后把对应的topic建上，客户端的message queue集合即会变大，这样对于broker的负载则由更多的broker group来进行分担。</p>

<p>并且由于每个group下面的topic的配置都是独立的，也就说可以让group1下面的那个topic的queue数量是4，其他group下的topic queue数量是2，这样group1则得到更大的负载。</p>

<h3>commit log</h3>

<p>虽然每个topic下面有很多message queue，但是message queue本身并不存储消息。真正的消息存储会写在CommitLog的文件，message queue只是存储CommitLog中对应的位置信息，方便通过message queue找到对应存储在CommitLog的消息。</p>

<p>不同的topic，message queue都是写到相同的CommitLog 文件，也就是说CommitLog完全的顺序写。</p>

<p>具体如下图：</p>

<p><img src="/images/rocketmq/broker-loadbalance.png" title="broker负载均衡" alt="broker负载均衡" /></p>

<h2>Producer</h2>

<p>Producer端，每个实例在发消息的时候，默认会轮询所有的message queue发送，以达到让消息平均落在不同的queue上。而由于queue可以散落在不同的broker，所以消息就发送到不同的broker下，如下图：</p>

<p><img src="/images/rocketmq/producer-loadbalance.png" title="生产者负载均衡" alt="生产者负载均衡" /></p>

<h2>Consumer负载均衡</h2>

<h3>集群模式</h3>

<p>在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。RocketMQ采用主动拉取的方式拉取并消费消息，在拉取的时候需要明确指定拉取哪一条message queue。</p>

<p>而每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时候会按照queue的数量和实例的数量平均分配queue给每个实例。</p>

<p>默认的分配算法是AllocateMessageQueueAveragely，如下图：</p>

<p><img src="/images/rocketmq/consumer-loadbalance1.png" title="消费者负载均衡1" alt="消费者负载均衡1" /></p>

<p>还有另外一种平均的算法是AllocateMessageQueueAveragelyByCircle，也是平均分摊每一条queue，只是以环状轮流分queue的形式，如下图：</p>

<p><img src="/images/rocketmq/consumer-loadbalance2.png" title="消费者负载均衡2" alt="消费者负载均衡2" /></p>

<p>需要注意的是，集群模式下，queue都是只允许分配只一个实例，这是由于如果多个实例同时消费一个queue的消息，由于拉取哪些消息是consumer主动控制的，那样会导致同一个消息在不同的实例下被消费多次，所以算法上都是一个queue只分给一个consumer实例，一个consumer实例可以允许同时分到不同的queue。</p>

<p>通过增加consumer实例去分摊queue的消费，可以起到水平扩展的消费能力的作用。而有实例下线的时候，会重新触发负载均衡，这时候原来分配到的queue将分配到其他实例上继续消费。</p>

<p>但是如果consumer实例的数量比message queue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。</p>

<h3>广播模式</h3>

<p>由于广播模式下要求一条消息需要投递到一个消费组下面所有的消费者实例，所以也就没有消息被分摊消费的说法。</p>

<p>在实现上，其中一个不同就是在consumer分配queue的时候，会所有consumer都分到所有的queue。</p>

<p><img src="/images/rocketmq/consumer-broadcast.png" title="消费者广播模式" alt="消费者广播模式" /></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/12/19/rocketmq-network-protocol/">RocketMQ——通信协议</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-12-19T20:49:23+08:00'><span class='date'>2016-12-19 Mon</span> <span class='time'>20:49</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>RocketMQ的通信协议其实很简单，但是无论是官方的用户手册，还是网上的博客，并没有很清晰简单地把其中所有的内容和原理讲明白。 对于需要扩展其他语言SDK的开发来说，意味着必须要深入到Java源码才能弄懂其概念。笔者通过深入源码，本文希望以尽量简短的语言描述清楚协议的每个字段及其意义。</p>

<p>无论是发送消息，拉取消息，还是发送心跳等所有的网络通讯层协议（客户端与broker/nameserver间，broker与nameserver间）都使用一套一样的协议。并且无论请求还是响应，协议是一样的，协议头的字段也是固定的。</p>

<h2>通讯协议</h2>

<p>协议分为以下四部分：</p>

<p><img src="/images/rocketmq/protocol.png" title="RocketMQ协议" alt="RocketMQ协议" /></p>

<p>其中后两部分是通讯的实际数据。前两段都是四个字节的整形，分别表示两段实际数据的长度。</p>

<ul>
<li><p>header: 协议的头，数据是序列化后的json。json的每个key字段都是固定的，不同的通讯请求字段不一样。后面解释</p></li>
<li><p>body: 请求的二进制实际数据。例如发送消息的网络请求中，body中传输实际的消息内容。</p></li>
<li><p>length:2 3 4 端整体的长度。四个字节整数。</p></li>
<li><p>header length: header的长度。四个字节整数。</p></li>
</ul>


<h3>Header</h3>

<p>协议header具体标识整个通讯请求的元数据，如请求什么，怎样的方式请求（异步/oneway）请求客户端的版本，语言，请求的具体参数等。</p>

<p>header是序列化的json,以下是json中的所有字段,并阐述起在请求和响应两个阶段的区别。</p>

<table>
<thead>
<tr>
<th> 字段      </th>
<th> 类型                   </th>
<th> Request                                                                                                                          </th>
<th> Response                                                                                   </th>
<th>   </th>
</tr>
</thead>
<tbody>
<tr>
<td> code      </td>
<td> 整数                   </td>
<td> 请求操作码。响应方通过code决定如何处理请求。                                                                                       </td>
<td> 响应码。0表示成功，非0表示错误码。                                                         </td>
<td>   </td>
</tr>
<tr>
<td> language  </td>
<td> 字符串                 </td>
<td> 标记请求方的语言类型，如JAVA。                                                                                                   </td>
<td> 应答方方的所使用的语言。                                                                   </td>
<td>   </td>
</tr>
<tr>
<td> version   </td>
<td> 整数                   </td>
<td> 请求方的版本号                                                                                                                   </td>
<td> 应答方的版本号                                                                             </td>
<td>   </td>
</tr>
<tr>
<td> opaque    </td>
<td> 整数                   </td>
<td> 在同一个连接上，标记是哪次请求。服务响应的时候会返回这个请求标识码，以达到请求方多线程中复用连接，在收到响应的时候找到对应的请求 </td>
<td> 原请求的opaque。应答方不做修改原值返回。                                                   </td>
<td>   </td>
</tr>
<tr>
<td> flag      </td>
<td> 整数                   </td>
<td> 通信层的标识位。标识这次通信的类型。                                                                                             </td>
<td> 通信层的标识位。标识这次通信的类型。                                                       </td>
<td>   </td>
</tr>
<tr>
<td> remark    </td>
<td> 字符串                 </td>
<td> 传输的自定义文本                                                                                                                 </td>
<td> 应答的文本信息。通常存放错误信息。                                                         </td>
<td>   </td>
</tr>
<tr>
<td> extFields </td>
<td> HashMap&lt;String,String> </td>
<td> 请求自定义字段。不同的请求会有不一样的参数列表，这里存放那些请求自定义的参数列表。                                               </td>
<td> 响应自定义字段。不同的响应会有不一样的参数列表，若有，这里则存放那些请求自定义的参数列表。 </td>
<td>   </td>
</tr>
</tbody>
</table>


<h4>Header详解：</h4>

<h5>code:</h5>

<p>请求/响应码。所有的请求码参考代码<code>RequestCode.java</code>。响应码则在<code>ResponseCode.java</code>中。</p>

<h5>language:</h5>

<p>由于要支持多语言，所以这一字段可以给通信双方知道对方通信层锁使用的开发语言。</p>

<h5>version:</h5>

<p>给通信层知道对方的版本号，响应方可以以此做兼容老版本等的特殊操作。</p>

<h5>opaque:</h5>

<p>请求标识码。在Java版的通信层中，这个只是一个不断自增的整形，为了收到应答方响应的的时候找到对应的请求。</p>

<p>flag： 按位(bit)解释。</p>

<p>第0位标识是这次通信是request还是response，0标识request, 1 标识response。</p>

<p>第1位标识是否是oneway请求，1标识oneway。应答方在处理oneway请求的时候，不会做出响应，请求方也无序等待应答方响应。</p>

<h5>remark:</h5>

<p>附带的文本信息。常见的如存放一些broker/nameserver返回的一些异常信息，方便开发人员定位问题。</p>

<h5>extFields：</h5>

<p>这个字段不通的请求/响应不一样，完全自定义。数据结构上是java的hashmap。在Java的每个RemotingCammand中，其实都带有一个CommandCustomHeader的属性成员，可以认为他是一个强类型的extFields，再最后传输的时候，这个CommandCustomHeader会被忽略，而传输前会把其中的所有字段全部都原封不动塞到extFields中，以作传输。</p>

<p>以发送消息为例(code=310)，发送消息的自定义header是SendMessageRequestHeaderV2（只是字段名对比SendMessageRequestHeader压缩了）。有以下字段：</p>

<pre><code>@CFNotNull
private String a;// producerGroup;
@CFNotNull
private String b;// topic;
@CFNotNull
private String c;// defaultTopic;
@CFNotNull
private Integer d;// defaultTopicQueueNums;
@CFNotNull
private Integer e;// queueId;
@CFNotNull
private Integer f;// sysFlag;
@CFNotNull
private Long g;// bornTimestamp;
@CFNotNull
private Integer h;// flag;
@CFNullable
private String i;// properties;
@CFNullable
private Integer j;// reconsumeTimes;
@CFNullable
private boolean k;// unitMode = false;
</code></pre>

<p>这些字段都会原封不动的去到extFields中做传输，最后看到的发送消息的请求header会类似如：</p>

<pre><code>{  
    "code":310,
    "extFields":{  
        "f":"0",
        "g":"1482158310125",
        "d":"4",
        "e":"0",
        "b":"TopicTest",
        "c":"TBW102",
        "a":"please_rename_unique_group_name",
        "j":"0",
        "k":"false",
        "h":"0",
        "i":"TAGS\u0001TagA\u0002WAIT\u0001true\u0002"
    },
    "flag":0,
    "language":"JAVA",
    "opaque":206,
    "version":79
}
</code></pre>

<p>注：其中fastjson把值为null的remark过滤了。</p>

<h2>请求码列表</h2>

<p>以下是截至到3.2.6的所有请求码列表</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>    // Broker 发送消息
</span><span class='line'>    public static final int SEND_MESSAGE = 10;
</span><span class='line'>    // Broker 订阅消息
</span><span class='line'>    public static final int PULL_MESSAGE = 11;
</span><span class='line'>    // Broker 查询消息
</span><span class='line'>    public static final int QUERY_MESSAGE = 12;
</span><span class='line'>    // Broker 查询Broker Offset
</span><span class='line'>    public static final int QUERY_BROKER_OFFSET = 13;
</span><span class='line'>    // Broker 查询Consumer Offset
</span><span class='line'>    public static final int QUERY_CONSUMER_OFFSET = 14;
</span><span class='line'>    // Broker 更新Consumer Offset
</span><span class='line'>    public static final int UPDATE_CONSUMER_OFFSET = 15;
</span><span class='line'>    // Broker 更新或者增加一个Topic
</span><span class='line'>    public static final int UPDATE_AND_CREATE_TOPIC = 17;
</span><span class='line'>    // Broker 获取所有Topic的配置（Slave和Namesrv都会向Master请求此配置）
</span><span class='line'>    public static final int GET_ALL_TOPIC_CONFIG = 21;
</span><span class='line'>    // Broker 获取所有Topic配置（Slave和Namesrv都会向Master请求此配置）
</span><span class='line'>    public static final int GET_TOPIC_CONFIG_LIST = 22;
</span><span class='line'>    // Broker 获取所有Topic名称列表
</span><span class='line'>    public static final int GET_TOPIC_NAME_LIST = 23;
</span><span class='line'>    // Broker 更新Broker上的配置
</span><span class='line'>    public static final int UPDATE_BROKER_CONFIG = 25;
</span><span class='line'>    // Broker 获取Broker上的配置
</span><span class='line'>    public static final int GET_BROKER_CONFIG = 26;
</span><span class='line'>    // Broker 触发Broker删除文件
</span><span class='line'>    public static final int TRIGGER_DELETE_FILES = 27;
</span><span class='line'>    // Broker 获取Broker运行时信息
</span><span class='line'>    public static final int GET_BROKER_RUNTIME_INFO = 28;
</span><span class='line'>    // Broker 根据时间查询队列的Offset
</span><span class='line'>    public static final int SEARCH_OFFSET_BY_TIMESTAMP = 29;
</span><span class='line'>    // Broker 查询队列最大Offset
</span><span class='line'>    public static final int GET_MAX_OFFSET = 30;
</span><span class='line'>    // Broker 查询队列最小Offset
</span><span class='line'>    public static final int GET_MIN_OFFSET = 31;
</span><span class='line'>    // Broker 查询队列最早消息对应时间
</span><span class='line'>    public static final int GET_EARLIEST_MSG_STORETIME = 32;
</span><span class='line'>    // Broker 根据消息ID来查询消息
</span><span class='line'>    public static final int VIEW_MESSAGE_BY_ID = 33;
</span><span class='line'>    // Broker Client向Client发送心跳，并注册自身
</span><span class='line'>    public static final int HEART_BEAT = 34;
</span><span class='line'>    // Broker Client注销
</span><span class='line'>    public static final int UNREGISTER_CLIENT = 35;
</span><span class='line'>    // Broker Consumer将处理不了的消息发回服务器
</span><span class='line'>    public static final int CONSUMER_SEND_MSG_BACK = 36;
</span><span class='line'>    // Broker Commit或者Rollback事务
</span><span class='line'>    public static final int END_TRANSACTION = 37;
</span><span class='line'>    // Broker 获取ConsumerId列表通过GroupName
</span><span class='line'>    public static final int GET_CONSUMER_LIST_BY_GROUP = 38;
</span><span class='line'>    // Broker 主动向Producer回查事务状态
</span><span class='line'>    public static final int CHECK_TRANSACTION_STATE = 39;
</span><span class='line'>    // Broker Broker通知Consumer列表变化
</span><span class='line'>    public static final int NOTIFY_CONSUMER_IDS_CHANGED = 40;
</span><span class='line'>    // Broker Consumer向Master锁定队列
</span><span class='line'>    public static final int LOCK_BATCH_MQ = 41;
</span><span class='line'>    // Broker Consumer向Master解锁队列
</span><span class='line'>    public static final int UNLOCK_BATCH_MQ = 42;
</span><span class='line'>    // Broker 获取所有Consumer Offset
</span><span class='line'>    public static final int GET_ALL_CONSUMER_OFFSET = 43;
</span><span class='line'>    // Broker 获取所有定时进度
</span><span class='line'>    public static final int GET_ALL_DELAY_OFFSET = 45;
</span><span class='line'>    // Namesrv 向Namesrv追加KV配置
</span><span class='line'>    public static final int PUT_KV_CONFIG = 100;
</span><span class='line'>    // Namesrv 从Namesrv获取KV配置
</span><span class='line'>    public static final int GET_KV_CONFIG = 101;
</span><span class='line'>    // Namesrv 从Namesrv获取KV配置
</span><span class='line'>    public static final int DELETE_KV_CONFIG = 102;
</span><span class='line'>    // Namesrv 注册一个Broker，数据都是持久化的，如果存在则覆盖配置
</span><span class='line'>    public static final int REGISTER_BROKER = 103;
</span><span class='line'>    // Namesrv 卸载一个Broker，数据都是持久化的
</span><span class='line'>    public static final int UNREGISTER_BROKER = 104;
</span><span class='line'>    // Namesrv 根据Topic获取Broker Name、队列数(包含读队列与写队列)
</span><span class='line'>    public static final int GET_ROUTEINTO_BY_TOPIC = 105;
</span><span class='line'>    // Namesrv 获取注册到Name Server的所有Broker集群信息
</span><span class='line'>    public static final int GET_BROKER_CLUSTER_INFO = 106;
</span><span class='line'>    public static final int UPDATE_AND_CREATE_SUBSCRIPTIONGROUP = 200;
</span><span class='line'>    public static final int GET_ALL_SUBSCRIPTIONGROUP_CONFIG = 201;
</span><span class='line'>    public static final int GET_TOPIC_STATS_INFO = 202;
</span><span class='line'>    public static final int GET_CONSUMER_CONNECTION_LIST = 203;
</span><span class='line'>    public static final int GET_PRODUCER_CONNECTION_LIST = 204;
</span><span class='line'>    public static final int WIPE_WRITE_PERM_OF_BROKER = 205;
</span><span class='line'>
</span><span class='line'>    // 从Name Server获取完整Topic列表
</span><span class='line'>    public static final int GET_ALL_TOPIC_LIST_FROM_NAMESERVER = 206;
</span><span class='line'>    // 从Broker删除订阅组
</span><span class='line'>    public static final int DELETE_SUBSCRIPTIONGROUP = 207;
</span><span class='line'>    // 从Broker获取消费状态（进度）
</span><span class='line'>    public static final int GET_CONSUME_STATS = 208;
</span><span class='line'>    // Suspend Consumer消费过程
</span><span class='line'>    public static final int SUSPEND_CONSUMER = 209;
</span><span class='line'>    // Resume Consumer消费过程
</span><span class='line'>    public static final int RESUME_CONSUMER = 210;
</span><span class='line'>    // 重置Consumer Offset
</span><span class='line'>    public static final int RESET_CONSUMER_OFFSET_IN_CONSUMER = 211;
</span><span class='line'>    // 重置Consumer Offset
</span><span class='line'>    public static final int RESET_CONSUMER_OFFSET_IN_BROKER = 212;
</span><span class='line'>    // 调整Consumer线程池数量
</span><span class='line'>    public static final int ADJUST_CONSUMER_THREAD_POOL = 213;
</span><span class='line'>    // 查询消息被哪些消费组消费
</span><span class='line'>    public static final int WHO_CONSUME_THE_MESSAGE = 214;
</span><span class='line'>
</span><span class='line'>    // 从Broker删除Topic配置
</span><span class='line'>    public static final int DELETE_TOPIC_IN_BROKER = 215;
</span><span class='line'>    // 从Namesrv删除Topic配置
</span><span class='line'>    public static final int DELETE_TOPIC_IN_NAMESRV = 216;
</span><span class='line'>    // Namesrv 通过 project 获取所有的 server ip 信息
</span><span class='line'>    public static final int GET_KV_CONFIG_BY_VALUE = 217;
</span><span class='line'>    // Namesrv 删除指定 project group 下的所有 server ip 信息
</span><span class='line'>    public static final int DELETE_KV_CONFIG_BY_VALUE = 218;
</span><span class='line'>    // 通过NameSpace获取所有的KV List
</span><span class='line'>    public static final int GET_KVLIST_BY_NAMESPACE = 219;
</span><span class='line'>
</span><span class='line'>    // offset 重置
</span><span class='line'>    public static final int RESET_CONSUMER_CLIENT_OFFSET = 220;
</span><span class='line'>    // 客户端订阅消息
</span><span class='line'>    public static final int GET_CONSUMER_STATUS_FROM_CLIENT = 221;
</span><span class='line'>    // 通知 broker 调用 offset 重置处理
</span><span class='line'>    public static final int INVOKE_BROKER_TO_RESET_OFFSET = 222;
</span><span class='line'>    // 通知 broker 调用客户端订阅消息处理
</span><span class='line'>    public static final int INVOKE_BROKER_TO_GET_CONSUMER_STATUS = 223;
</span><span class='line'>
</span><span class='line'>    // Broker 查询topic被谁消费
</span><span class='line'>    // 2014-03-21 Add By shijia
</span><span class='line'>    public static final int QUERY_TOPIC_CONSUME_BY_WHO = 300;
</span><span class='line'>
</span><span class='line'>    // 获取指定集群下的所有 topic
</span><span class='line'>    // 2014-03-26
</span><span class='line'>    public static final int GET_TOPICS_BY_CLUSTER = 224;
</span><span class='line'>
</span><span class='line'>    // 向Broker注册Filter Server
</span><span class='line'>    // 2014-04-06 Add By shijia
</span><span class='line'>    public static final int REGISTER_FILTER_SERVER = 301;
</span><span class='line'>    // 向Filter Server注册Class
</span><span class='line'>    // 2014-04-06 Add By shijia
</span><span class='line'>    public static final int REGISTER_MESSAGE_FILTER_CLASS = 302;
</span><span class='line'>    // 根据 topic 和 group 获取消息的时间跨度
</span><span class='line'>    public static final int QUERY_CONSUME_TIME_SPAN = 303;
</span><span class='line'>    // 获取所有系统内置 Topic 列表
</span><span class='line'>    public static final int GET_SYSTEM_TOPIC_LIST_FROM_NS = 304;
</span><span class='line'>    public static final int GET_SYSTEM_TOPIC_LIST_FROM_BROKER = 305;
</span><span class='line'>
</span><span class='line'>    // 清理失效队列
</span><span class='line'>    public static final int CLEAN_EXPIRED_CONSUMEQUEUE = 306;
</span><span class='line'>
</span><span class='line'>    // 通过Broker查询Consumer内存数据
</span><span class='line'>    // 2014-07-19 Add By shijia
</span><span class='line'>    public static final int GET_CONSUMER_RUNNING_INFO = 307;
</span><span class='line'>
</span><span class='line'>    // 查找被修正 offset (转发组件）
</span><span class='line'>    public static final int QUERY_CORRECTION_OFFSET = 308;
</span><span class='line'>
</span><span class='line'>    // 通过Broker直接向某个Consumer发送一条消息，并立刻消费，返回结果给broker，再返回给调用方
</span><span class='line'>    // 2014-08-11 Add By shijia
</span><span class='line'>    public static final int CONSUME_MESSAGE_DIRECTLY = 309;
</span><span class='line'>
</span><span class='line'>    // Broker 发送消息，优化网络数据包
</span><span class='line'>    public static final int SEND_MESSAGE_V2 = 310;
</span><span class='line'>
</span><span class='line'>    // 单元化相关 topic
</span><span class='line'>    public static final int GET_UNIT_TOPIC_LIST = 311;
</span><span class='line'>    // 获取含有单元化订阅组的 Topic 列表
</span><span class='line'>    public static final int GET_HAS_UNIT_SUB_TOPIC_LIST = 312;
</span><span class='line'>    // 获取含有单元化订阅组的非单元化 Topic 列表
</span><span class='line'>    public static final int GET_HAS_UNIT_SUB_UNUNIT_TOPIC_LIST = 313;
</span><span class='line'>    // 克隆某一个组的消费进度到新的组
</span><span class='line'>    public static final int CLONE_GROUP_OFFSET = 314;
</span><span class='line'>
</span><span class='line'>    // 查看Broker上的各种统计信息
</span><span class='line'>    public static final int VIEW_BROKER_STATS_DATA = 315;
</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/3">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/index.html">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>最近博文</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2020/11/26/rocketmq-consumer-allocate/">为什么在一段时间内RocketMQ的队列同时分配给了两个消费者？详细剖析消费者负载均衡中的坑（上）</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/06/08/rocketmq-message-dedup/">消息幂等（去重）通用解决方案，RocketMQ</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/06/01/mysql-deadlock-index-merge/">记一次因索引合并导致的MySQL死锁分析过程</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/05/25/elastic-job-timmer-active-standby/">Elastic Job从单点到高可用、同城主备、同城双活</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/05/22/dubbo-refernececonfig-is-not-destroyed-when-finalize/">[DUBBO] ReferenceConfig(null) Is Not DESTROYED When FINALIZE分析及解决</a>
      </li>
    
  </ul>
</section>

<section>
    <div class="LI-profile-badge"  data-version="v1" data-size="medium" data-locale="en_US" data-type="vertical" data-theme="light" data-vanity="jaskeylam"><a class="LI-simple-link" href='https://cn.linkedin.com/in/jaskeylam?trk=profile-badge'>Jaskey Lam</a></div>
</section>


<section>
  <h1>StackOverflow</h1>
  <a href="http://stackoverflow.com/users/">
	<img src="http://stackoverflow.com/users/flair/2087628.png" width="208" height="58" 
		 alt="profile for Jaskey at Stack Overflow, Q&amp;A for professional and enthusiast programmers" 
		 title="profile for Jaskey at Stack Overflow, Q&amp;A for professional and enthusiast programmers"
	>
  </a>
</section>


<section>
  <h1>Jaskey Lam的微博</h1>
  <ul id="weibo">
    <li>
		<iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="yes" 
				src="https://widget.weibo.com/weiboshow/index.php?
				language=&
				width=0&
				height=550&
				fansRow=0& 
				ptype=1&
				speed=300&
				skin=9&
				isTitle=0&
				noborder=0&
				isWeibo=1&
				isFans=0&
				uid=1762728080&
				verifier=4b318246&
				dpc=1">
		</iframe>
    </li>
  </ul>
</section>

<section>
	<h1>我的豆瓣<h1>
  <div>
    <script type="text/javascript" 
    src="http://www.douban.com/service/badge/linjunjie1103/?
    selection=&
    amp;picsize=small&
    amp;hidelogo=&
    amp;show=collection&
    amp;n=9&
    amp;cat=movie%7Cbook&
    amp;columns=3">
    </script>  
  </div>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/Jaskey">@Jaskey</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'Jaskey',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2021 - Jaskey Lam -
  <span class="credit">联系邮箱:linjunjie1103@gmail.com</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
