<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | 薛定谔的风口猪]]></title>
  <link href="https://Jaskey.github.io/blog/categories/java/atom.xml" rel="self"/>
  <link href="https://Jaskey.github.io/"/>
  <updated>2020-05-19T00:45:11+08:00</updated>
  <id>https://Jaskey.github.io/</id>
  <author>
    <name><![CDATA[Jaskey Lam]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[利用Java进程名进行jstat -gc]]></title>
    <link href="https://Jaskey.github.io/blog/2020/05/13/stat-gc-with-process-name/"/>
    <updated>2020-05-13T16:29:07+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/05/13/stat-gc-with-process-name</id>
    <content type="html"><![CDATA[<p>需要实时观看GC的情况，我们可以类似如下命令进行监控</p>

<pre><code class="bash"> jstat -gc $pid 100 10 
</code></pre>

<p>但是这里需要一个进程号，很麻烦，每个Java进程在不同机器或者启动不一样就会不一样，对于自动监控脚本或者是如果需要定位应用刚开始启动时候gc的问题时，当你手动敲完命令拿到pid的时候，可能都凉了。</p>

<p>对此写了一个简单的shell脚本可以传入进程名去执行jstat</p>

<p>gcstat.sh:</p>

<pre><code class="bash">#! /bin/bash

process=$1
interval=$2
count=$3
pid=$(ps -ef | grep java | grep $process | grep -v grep | awk '{print $2}') 
echo $pid
echo $interval
echo $count
</code></pre>

<p>使用：</p>

<pre><code class="bash">./gcstat.sh  processName 1000 5
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[自定义ShardingSphere的加解密器]]></title>
    <link href="https://Jaskey.github.io/blog/2020/04/29/user-defined-shardingsphere-encryptor/"/>
    <updated>2020-04-29T20:44:03+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/04/29/user-defined-shardingsphere-encryptor</id>
    <content type="html"><![CDATA[<p>默认的Sharding Sphere 支持AES和MD5两种加密器。有些时候可能需要自定义使用自己的加解密算法，如AES的具体实现不一样等。网上公开的并没有直接的指引，通过部分源码的阅读，找到了可行的方式。需要三步：</p>

<h2>1.实现自定义解密器 （实现ShardingEncryptor 接口）</h2>

<pre><code class="java">public class TestShardingEncryptor implements ShardingEncryptor {
        private Properties properties = new Properties();

         @Override
         public String getType() {
                return "TEST";
          }


          @Override
         public void init() {

         }

         @Override
         public String encrypt(final Object plaintext) {
             return "TEST-"+String.valueOf(plaintext);
         }

         @Override
        public Object decrypt(final String ciphertext) {
             return ciphertext.replaceAll("TEST-","");
         }
}
</code></pre>

<p>其中<code>getType</code>返回的字符串（本例为&#8221;TEST&#8221;）即为本加解密器的类型（后续使用的时候会使用）</p>

<h2>2.创建org.apache.shardingsphere.spi.encrypt.ShardingEncryptor 文件</h2>

<p>需要创建一个文件名为<code>org.apache.shardingsphere.spi.encrypt.ShardingEncryptor</code>放入resources路径下的<code>\META-INF\services</code></p>

<p><img src="http://jaskey.github.io/images/shardingsphere/sharding-encryptor-file-path.png" title="sharding-encryptor-file-path" alt="sharding-encryptor-file-path" /></p>

<p>文件的内容就是类名全称，如：</p>

<p>com.yourcompany.TestShardingEncryptor</p>

<h2>3.配置使用此自定义类</h2>

<h4>Java配置模式：</h4>

<p>如果未使用Spring Boot，需要显示用代码配置</p>

<pre><code class="java">EncryptorRuleConfiguration encryptorConfig = new EncryptorRuleConfiguration("TEST", props);
</code></pre>

<h4>Spring Boot配置模式：</h4>

<p>如果使用的是Spring Boot配置模式，则需要如下配置</p>

<pre><code class="java">spring.shardingsphere.encrypt.encryptors.my_encryptor.type=TEST  
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java GC垃圾收集器这点小事]]></title>
    <link href="https://Jaskey.github.io/blog/2020/04/27/gc-basics/"/>
    <updated>2020-04-27T15:08:05+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/04/27/gc-basics</id>
    <content type="html"><![CDATA[<p>​    对于大多数的应用来说，其实默认的JVM设置就够用了，但当你意识到有GC引起的性能问题、并且仅仅加大堆内存空间也解决不了的时候，那你就应该考虑下GC的调优了。但对于大多数程序员来说，这是很麻烦的，因为调优需要很多耐心，并且需要知道垃圾回收器的运作原理及背后对应用的影响。本文是high-level层面的关于Java垃圾回收器的总览，并以例子的形式去讲解性能定位的一些问题。</p>

<p>​    正文开始。</p>

<p>​    Java提供了很多种垃圾回收器，会在gc运行的线程中搭配着不同的算法。不同的回收器工作原理不一样，优缺点也不同。最重要的是无论哪一种回收器都会&#8221;stop the world&#8221;。就是说，在收集和回收的过程中，你的应用程序（或多或少）都会处于暂停状态，只不过不同算法的stop the world的表现有所不同。有些算法一直都会闲置不工作直到必须要垃圾收集才开始工作，然后就暂停应用程序很长的时间；而有一些则能和应用程序同步的进行所以在“stop the world”阶段就会有更少的暂停。选择最合适的算法要取决于你的目标：你是想优化整体的吞吐量即便不时地就会长时间暂停也是可以接受的，还是说你是想得到低延迟的优化通过分散各个时间以得到每时每刻都低延迟。</p>

<p>​    为了增强垃圾回收的过程，Java（准确的说是 HotSpot JVM）把堆分成了两个代，年轻代和年老代（还有一个叫永久代的区域不在我们本文讨论范围）</p>

<p><img src="http://jaskey.github.io/images/gc/hotspot-heap.png" title="hotspot-heap" alt="hotspot-heap" /></p>

<p>​    年轻代是一些“年轻”的对象存放的地方，而年轻代还会继续分为以下三个区域：</p>

<ol>
<li>伊甸区（Eden Space）</li>
<li>幸存区1（Survivor Space 1）</li>
<li>幸存区2（Survivor Space 2）</li>
</ol>


<p>​    默认情况下，伊甸区是大于两个幸存者区的总和的。例如在我的Mac OS X上的64位HotSpot JVM上，伊甸区占了大概年轻代76%的区域。所有的对象一开始都会在伊甸区创建，当伊甸区满了之后，就会触发一次次要的垃圾回收（minor gc），期间新对象会快速地被检查是否可以进行垃圾回收。一旦发现那些对象已经死亡（dead），也就是说没有再被其他对象引用了（这里先简单忽略掉引用的具体类型带来的一些差异，不在本文讨论），就会被标记为死亡然后被垃圾回收掉。而其中“幸存”的对象就会被移到其中的一个空的Survivor Space。你可能会问，具体移动到哪一个幸存区呢？要回答这个问题，首先我们先聊一下幸存区的设计。</p>

<p>​    之所以设计两个幸存区，是为了避免内存碎片。假设只有一个幸存区（然后我们把幸存区想象成一个内存中连续的数组），当年轻代的gc在这个数组上运行了一遍后，会标记一些死亡对象然后删除掉，这样的话势必会在内存中留下一些空洞的区域（原来的对象存活的位置），那么就有必要做压缩了。所以为了避免做压缩，HotSpot JVM就从一个幸存者区复制所有幸存的对象到另外一个（空的）幸存者区里，这样就没有空洞了。这里我们讲到了压缩，顺便提一下年老代的垃圾回收器（除了CMS）在进行年老代垃圾回收的时候都会进行压缩以避免内存碎片。</p>

<p>​    简单地说，次要的垃圾回收（当伊甸区满的时候）就会把存活的对象从伊甸区和其中一个幸存区（gc日志中以“from”呈现）左右捣腾地搬到另外一个幸存区（又叫“to”）。这样会一直的持续下去直到以下的条件发生：</p>

<ol>
<li>对象达到了最大的晋升时间阈值（<em>maximum tenuring threshold</em>），就是说在年轻代被左右捣腾得足够久了，媳妇熬成婆。</li>
<li>幸存区已经没有空间去接受新生的对象了（后面会讲到）</li>
</ol>


<p>​    以上条件发生后，对象就会被移动到年老代了。下面用一个具体的例子来理解下。假设我们有以下的应用程序，它会在初始化的时候创建一些长期存活的对象，也会在运行的过程中不断的创建很多存活时间很短的对象（例如我们的web服务器程序在处理请求的时候会不断分配存活时间很短的对象）</p>

<pre><code class="java">private static void createFewLongLivedAndManyShortLivedObjects() {
        HashSet&lt;Double&gt; set = new HashSet&lt;Double&gt;();

        long l = 0;
        for (int i=0; i &lt; 100; i++) {
            Double longLivedDouble = new Double(l++);
            set.add(longLivedDouble);  // 加到集合里，让这些对象能持续的存活
        }

        while(true) { // 不断地创建一些存活时间短的对象（这里在实际代码中比较极端，仅为演示用）
            Double shortLivedDouble = new Double(l++);
        }
}
</code></pre>

<p> 在运行这个程序的过程中我们启用GC的部分日志参数：</p>

<pre><code class="java">-Xmx100m                     // 分配100MV的堆内存
-XX:-PrintGC                 // 开启GC日志打印
-XX:+PrintHeapAtGC           // 开启GC日志打印堆信息
-XX:MaxTenuringThreshold=15  // 为了让对象能在年轻代呆久一点
-XX:+UseConcMarkSweepGC      // 暂时先忽略这个配置，后面会讲到
-XX:+UseParNewGC             // 暂时先忽略这个配置，后面会讲到
</code></pre>

<p>gc 日志会显示垃圾收集前后的情况如下：</p>

<pre><code class="html">Heap &lt;b&gt;before&lt;/b&gt; GC invocations=5 (full 0):
 par new (&lt;u&gt;young&lt;/u&gt;) generation total 30720K, used 28680K
  eden space 27328K,   &lt;b&gt;100%&lt;/b&gt; used
  from space 3392K,   &lt;b&gt;39%&lt;/b&gt; used
  to   space 3392K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 68288K, used &lt;b&gt;0K&lt;/b&gt; &lt;br/&gt;
Heap &lt;b&gt;after&lt;/b&gt; GC invocations=6 (full 0):
 par new generation (&lt;u&gt;young&lt;/u&gt;) total 30720K, used 1751K
  eden space 27328K,   &lt;b&gt;0%&lt;/b&gt; used
  from space 3392K,   &lt;b&gt;51%&lt;/b&gt; used
  to   space 3392K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 68288K, used &lt;b&gt;0K&lt;/b&gt;
</code></pre>

<p>​    从这个日志里我们能得到以下信息。第一，在这次gc之前，已经发生了5次的minor gc了（所以这次是第6次）。第二，伊甸区占用了100%所以触发了这次的gc。第三，其中一个幸存区域已经使用了39%的空间（还有不少可用空间）。而这次垃圾收集结束后，我们能看到伊甸区就被清空了（0%）然后幸存者区域上升到51%。这意味着伊甸区和其中一个幸存区里存活的对象已经被移动到另外一个幸存区了，然后死亡的对象已经被垃圾回收了。怎么推断的死亡对象被回收了呢？我们看到伊甸区原来是比幸存区要大的（27328K vs 3392K），而后面幸存区的空间大小仅仅是轻微的上升（伊甸区被清空了），所以大量的对象肯定是被垃圾回收了。而我们再看看年老代，年老代是一直都是空的，无论是这次垃圾回收前还是后（回想一下，我们设置了晋升阈值为15）。</p>

<p>​    下面我们再试另外一个实验。这次用多线程不断的创建存活时间很短的对象。直觉上判断，依旧应该没有对象会上升到年老代才对，因为minor gc就应该可以把这些对象清理干净。我们来看看实际情况如何</p>

<pre><code class="java">private static void createManyShortLivedObjects() {
        final int NUMBER_OF_THREADS = 100;
        final int NUMBER_OF_OBJECTS_EACH_TIME = 1000000;

        for (int i=0; i&lt;NUMBER_OF_THREADS; i++) {
            new Thread(() -&gt; {
                    while(true) {
                        for (int i=0; i&lt;NUMBER_OF_OBJECTS_EACH_TIME; i++) {
                            Double shortLivedDouble = new Double(1.0d);
                        }
                        sleepMillis(1);
                    }
                }
            }).start();
        }
    }
}
</code></pre>

<p>这次，我们只给10MB的内存，然后看看GC日志</p>

<pre><code class="java">Heap &lt;b&gt;before&lt;/b&gt; GC invocations=0 (full 0):
 par new (&lt;u&gt;young&lt;/u&gt;) generation total 3072K, used 2751K
  eden space 2752K,  99% used
  from space 320K,   0% used
  to   space 320K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 6848K, used &lt;b&gt;0K&lt;/b&gt; &lt;br/&gt;
Heap &lt;b&gt;after&lt;/b&gt; GC invocations=1 (full 0):
 par new generation  (&lt;u&gt;young&lt;/u&gt;)  total 3072K, used 318K
  eden space 2752K,   0% used
  from space 320K,  99% used
  to   space 320K,   0% used
 concurrent mark-sweep (&lt;u&gt;old&lt;/u&gt;) generation total 6848K, used &lt;b&gt;76K&lt;/b&gt;
</code></pre>

<p>​    从日志上看，并不如我们一开始想的那样。这次，老年代在第一次minor gc之后，接受了一些对象。实际上这些对象都是存活时间很短的对象，并且我们设置了晋升阈值是15次，再而且日志里显示的gc只是第一次垃圾收集。这个现象背后实际上是这样的：应用程序创建了大量的对象在伊甸区，minor gc启动的时候尝试去回收，但是大多数的这些存活时间很短的对象实际上都是active的（被一个运行中的线程引用着）。那么年轻代的垃圾收集器就只好把这些对象移动到年老代了。这其实是一个不好的现象，因为这些被移到到年老代的对象其实是过早衰老了（prematurely aged），它们只有在老年代的major gc才能被回收，而major gc通常会耗时更长。对于某些垃圾算法例如CMS，major gc会在年老代70%内存占据后出发。这个值可以通过参数修改<code>-XX:CMSInitiatingOccupancyFraction=70</code></p>

<p>​    怎么样防止这些短暂存活的对象过早衰老呢？有几个方法，其中一个理论上可行的方法是估计这些活跃的短暂存活对象的数量，然后设置合理的年轻代大小。我们下面来试试：</p>

<ul>
<li>年轻代默认是整个堆大小的1/3，这次我们通过 <code>-XX:NewRatio=1</code> 来修改其大小让他内存更大些（大约3.4MB，原来是3MB）</li>
<li>同时调整幸存者区的大小：<code>-XX:SurvivorRatio=1</code> （大约1.6MB一个区，原来是0.3MB）</li>
</ul>


<p>问题就解决了。经过8次的minor gc，年老代依旧是空的</p>

<pre><code class="html">Heap &lt;b&gt;before&lt;/b&gt; GC invocations=7 (full 0):
 par new generation   total 3456K, used 2352K
  eden space 1792K,  99% used
  from space 1664K,  33% used
  to   space 1664K,   0% used
 concurrent mark-sweep generation total 5120K, used &lt;b&gt;0K&lt;/b&gt; &lt;br/&gt;
Heap &lt;b&gt;after&lt;/b&gt; GC invocations=8 (full 0):
 par new generation   total 3456K, used 560K
  eden space 1792K,   0% used
  from space 1664K,  33% used
  to   space 1664K,   0% used [
 concurrent mark-sweep generation total 5120K, used &lt;b&gt;0K&lt;/b&gt;
</code></pre>

<p>​    对于GC调优，没有银弹。这里只是简单地示意。对于实际的应用，需要不断的修改配置试错来找到最佳配置。例如，这次其实我们也可以将堆的总大小调大一倍来解决此问题。</p>

<h2>垃圾回收算法</h2>

<p>​    接下来我们来看看具体的垃圾回收算法。Hotspot JVM针对年轻代和年老代有多个不同的算法。从宏观层面上看，有三种类型的垃圾回收算法，每一类都有单独的<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/collectors.html">性能特性</a>:</p>

<p><strong>serial collector</strong> ：使用一条线程进行所有的垃圾回收工作，相对来说也是高效的因为没有线程之间的通信。适用于单处理器的机器。使用<code>-XX:+UseSerialGC.</code>启用</p>

<p><strong>parallel collector</strong> (同时也称作吞吐回收器) ：使用多线程进行垃圾回收，这样能显著的降低垃圾回收的负荷。设计来适用于这样的应用：拥有中等或大数据集的，运行在多核处理器或多线程的硬件</p>

<p><strong>concurrent collector</strong>： 大部分的垃圾回收工作会同步的进行（不阻塞应用的运行）以维持短暂的GC暂停时间。它是设计给中等或大数据集的、响应时间比整体的吞吐量要更重要的应用，因为用这种算法去降低GC的停顿会一定程度降低应用的性能。</p>

<p><img src="http://jaskey.github.io/images/gc/gc-compared.png" title="gc-compared" alt="gc-compared" /></p>

<p>​    HotSpot JVM可以让我们选择不同的GC算法去回收年轻代和年老代，但是某些算法是需要配套的使用才兼容的。例如，你不能选择<em>Parallel Scavenge</em>去回收年轻代的同时，使用CMS收集器去回收年老代因为这两个收集器是不兼容的。以下是兼容的收集器的示意图</p>

<p><img src="http://jaskey.github.io/images/gc/gc-collectors-pairing.jpg" title="gc-collectors-pairing" alt="gc-collectors-pairing" /></p>

<ol>
<li>“Serial”是一个stop-the-world，复制算法的垃圾收集器，使用一条GC线程。</li>
<li>“Parallel Scavenge”是一个stop-the-world、采用复制算法的垃圾收集器，但是使用多条GC线程。</li>
<li>ParNew是一个stop-the-world，复制算法的收集器，使用多条GC线程。它和Parallel Scavenge的区别是它做了一些增强以适应搭配CMS使用。例如ParNew会做必要的同步（synchronization ）以便它能在CMS的同步阶段运行。</li>
<li>Serial Old 是一个stop-the-world，采用标记-清除-压缩算法的回收器，使用一条GC线程</li>
<li>CMS（Concurrent Mark Sweep）是一个同步能力最强、低延迟的垃圾回收器</li>
<li>Parallel Old是一个压缩算法的垃圾回收器，使用多个GC线程。</li>
</ol>


<p>​    对于服务端的应用程序（需要处理客户端请求）来说，使用CMS+ParNew是不错的选择。</p>

<p>我在大概10GB堆内存的程序中使用过也能保持响应时间稳定和短暂的GC暂停时间。我认识的一些开发者使用Parallel collectors (<em>Parallel Scavenge</em> + <em>Parallel Old</em>) ，效果也不错。</p>

<p>​    其中一件需要注意的事是CMS已经宣布废弃了，会被Oralce推荐使用一个新的同步收集器取代， <a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/G1.html">Garbage-First</a> 简称 <strong>G1</strong>, 一个最先由Java推出的垃圾收集器</p>

<p>​    G1是一个服务端类型（server-style）的垃圾回收器，针对多处理器、大内存的计算机使用。它能尽可能地满足一个GC延迟时间的目标，同时也有很高的吞吐量</p>

<p>​    <strong>G1</strong> 会同时在年轻代和年老代进行工作。它针对大堆有专门的优化（>10GB）。我没有亲身尝试过G1，我团队里的开发者仍然使用的CMS，所以我还不能对两者进行比较。但通过快速的搜索之后，我找到了一个性能对比说CMS会比G1更好（<a href="http://blog.novatec-gmbh.de/g1-action-better-cms/">CMS outperforming</a> <a href="https://dzone.com/articles/g1-vs-cms-vs-parallel-gc">G1</a>）。我倾向于谨慎，但G1应该是不错的。我们能靠以下参数启动</p>

<pre><code>-XX:+UseG1GC
</code></pre>

<p>注：以上由本人摘选翻译自<a href="https://codeahoy.com/2017/08/06/basics-of-java-garbage-collection/">https://codeahoy.com/2017/08/06/basics-of-java-garbage-collection/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于Sharding Sphere实现数据“一键脱敏”]]></title>
    <link href="https://Jaskey.github.io/blog/2020/03/18/sharding-sphere-data-desensitization/"/>
    <updated>2020-03-18T20:53:00+08:00</updated>
    <id>https://Jaskey.github.io/blog/2020/03/18/sharding-sphere-data-desensitization</id>
    <content type="html"><![CDATA[<p>在真实业务场景中，数据库中经常需要存储某些客户的关键性敏感信息如：身份证号、银行卡号、姓名、手机号码等，此类信息按照合规要求，通常需要实现加密存储以满足合规要求。</p>

<h3>痛点一：</h3>

<p>通常的解决方案是我们书写SQL的时候，把对应的加密字段手动进行加密再进行插入，在查询的时候使用之前再手动进行解密。此方法固然可行，但是使用起来非常不便捷且繁琐，使得日常的业务开发与存储合规的细节紧耦合</p>

<h3>痛点二：</h3>

<p>对于一些为了快速上线而一开始没有实现合规脱敏的系统，如何比较快速的使得已有业务满足合规要求的同时，尽量减少对原系统的改造。（通常的这个过程至少包括：1.新增脱敏列的存储 2.同时做数据迁移 3.业务的代码做兼容逻辑等）。</p>

<p>Apache ShardingSphere下面存在一个数据脱敏模块，此模块集成的常用的数据脱敏的功能。其基本原理是对用户输入的SQL进行解析拦截，并依靠用户的脱敏配置进行SQL的改写，从而实现对原文字段的加密及加密字段的解密。最终实现对用户无感的加解密存储、查询。</p>

<h2>脱敏配置Quick Start——Spring 显示配置：</h2>

<p>以下介绍基于Spring如何快速让系统支持脱敏配置。</p>

<h3>1.引入依赖</h3>

<pre><code>&lt;!-- for spring namespace --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt;
    &lt;version&gt;${sharding-sphere.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<h3>2.创建脱敏配置规则对象</h3>

<p>在创建数据源之前，需要准备一个EncryptRuleConfiguration进行脱敏的配置，以下是一个例子，对于同一个数据源里两张表card_info，pay_order的不同字段进行AES的加密</p>

<pre><code>private EncryptRuleConfiguration getEncryptRuleConfiguration() {
Properties props = new Properties();

//自带aes算法需要
props.setProperty("aes.key.value", aeskey);
EncryptorRuleConfiguration encryptorConfig = new EncryptorRuleConfiguration("AES", props);

//自定义算法
//props.setProperty("qb.finance.aes.key.value", aeskey);
//EncryptorRuleConfiguration encryptorConfig = new EncryptorRuleConfiguration("QB-FINANCE-AES", props);

EncryptRuleConfiguration encryptRuleConfig = new EncryptRuleConfiguration();
encryptRuleConfig.getEncryptors().put("aes", encryptorConfig);

//START: card_info 表的脱敏配置
{
    EncryptColumnRuleConfiguration columnConfig1 = new EncryptColumnRuleConfiguration("", "name", "", "aes");
    EncryptColumnRuleConfiguration columnConfig2 = new EncryptColumnRuleConfiguration("", "id_no", "", "aes");
    EncryptColumnRuleConfiguration columnConfig3 = new EncryptColumnRuleConfiguration("", "finshell_card_no", "", "aes");
    Map&lt;String, EncryptColumnRuleConfiguration&gt; columnConfigMaps = new HashMap&lt;&gt;();
    columnConfigMaps.put("name", columnConfig1);
    columnConfigMaps.put("id_no", columnConfig2);
    columnConfigMaps.put("finshell_card_no", columnConfig3);
    EncryptTableRuleConfiguration tableConfig = new EncryptTableRuleConfiguration(columnConfigMaps);
    encryptRuleConfig.getTables().put("card_info", tableConfig);
}
//END: card_info 表的脱敏配置

//START: pay_order 表的脱敏配置
{
    EncryptColumnRuleConfiguration columnConfig1 = new EncryptColumnRuleConfiguration("", "card_no", "", "aes");
    Map&lt;String, EncryptColumnRuleConfiguration&gt; columnConfigMaps = new HashMap&lt;&gt;();
    columnConfigMaps.put("card_no", columnConfig1);
    EncryptTableRuleConfiguration tableConfig = new EncryptTableRuleConfiguration(columnConfigMaps);
    encryptRuleConfig.getTables().put("pay_order", tableConfig);
}

log.info("脱敏配置构建完成:{} ", encryptRuleConfig);
return encryptRuleConfig;
</code></pre>

<p>}</p>

<p>说明：</p>

<ol>
<li>创建 EncryptColumnRuleConfiguration 的时候有四个参数，前两个参数分表叫plainColumn、cipherColumn，其意思是数据库存储里面真实的两个列（名文列、脱敏列），对于新的系统，只需要设置脱敏列即可，所以以上示例为plainColumn为&#8221;&ldquo;。</li>
<li>创建EncryptTableRuleConfiguration 的时候需要传入一个map，这个map存的value即#1中说明的EncryptColumnRuleConfiguration ，而其key则是一个逻辑列，对于新系统，此逻辑列即为真实的脱敏列。Sharding Shpere在拦截到SQL改写的时候，会按照用户的配置，把逻辑列映射为名文列或者脱敏列（默认）如下的示例</li>
</ol>


<p><img src="http://jaskey.github.io/images/shardingsphere/basic.png" title="shardings sphere basic" alt="shardings sphere basic" /></p>

<h3>3.使用Sharding Sphere的数据源进行管理</h3>

<p>把原始的数据源包装一层</p>

<pre><code>@Bean("tradePlatformDataSource")
public DataSource dataSource(@Qualifier("druidDataSource") DataSource ds) throws SQLException {
    return EncryptDataSourceFactory.createDataSource(ds, getEncryptRuleConfiguration(), new Properties());

}
</code></pre>

<h2>脱敏配置Quick Start——Spring Boot版：</h2>

<p>以下步骤使用Spring Boot管理，可以仅用配置文件解决：</p>

<p>1.引入依赖</p>

<pre><code>&lt;!-- for spring boot --&gt;

&lt;dependency&gt;
&lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;${sharding-sphere.version}&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- for spring namespace --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt;
    &lt;version&gt;${sharding-sphere.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<ol>
<li>Spring 配置文件</li>
</ol>


<pre><code>
spring.shardingsphere.datasource.name=ds
spring.shardingsphere.datasource.ds.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.ds.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds.url=xxxxxxxxxxxxx
spring.shardingsphere.datasource.ds.username=xxxxxxx
spring.shardingsphere.datasource.ds.password=xxxxxxxxxxxx



# 默认的AES加密器
spring.shardingsphere.encrypt.encryptors.encryptor_aes.type=aes
spring.shardingsphere.encrypt.encryptors.encryptor_aes.props.aes.key.value=hkiqAXU6Ur5fixGHaO4Lb2V2ggausYwW

# card_info 姓名 AES加密
spring.shardingsphere.encrypt.tables.card_info.columns.name.cipherColumn=name
spring.shardingsphere.encrypt.tables.card_info.columns.name.encryptor=encryptor_aes

# card_info 身份证 AES加密
spring.shardingsphere.encrypt.tables.card_info.columns.id_no.cipherColumn=id_no
spring.shardingsphere.encrypt.tables.card_info.columns.id_no.encryptor=encryptor_aes

# card_info 银行卡号 AES加密
spring.shardingsphere.encrypt.tables.card_info.columns.finshell_card_no.cipherColumn=finshell_card_no
spring.shardingsphere.encrypt.tables.card_info.columns.finshell_card_no.encryptor=encryptor_aes

# pay_order 银行卡号 AES加密
spring.shardingsphere.encrypt.tables.pay_order.columns.card_no.cipherColumn=card_no
spring.shardingsphere.encrypt.tables.pay_order.columns.card_no.encryptor=encryptor_aes
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RocketMQ——消息文件过期原理]]></title>
    <link href="https://Jaskey.github.io/blog/2017/02/16/rocketmq-clean-commitlog/"/>
    <updated>2017-02-16T11:49:23+08:00</updated>
    <id>https://Jaskey.github.io/blog/2017/02/16/rocketmq-clean-commitlog</id>
    <content type="html"><![CDATA[<p><a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management//" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a> 文中提过，所有的消费均是客户端发起Pull请求的，告诉消息的offset位置，broker去查询并返回。但是有一点需要非常明确的是，消息消费后，消息其实<strong>并没有</strong>物理地被清除，这是一个非常特殊的设计。本文来探索此设计的一些细节。</p>

<h2>消费完后的消息去哪里了？</h2>

<p>消息的存储是一直存在于CommitLog中的。而由于CommitLog是以文件为单位（而非消息）存在的，CommitLog的设计是只允许顺序写的，且每个消息大小不定长，所以这决定了消息文件几乎不可能按照消息为单位删除（否则性能会极具下降，逻辑也非常复杂）。所以消息被消费了，消息所占据的物理空间并不会立刻被回收。</p>

<p>但消息既然一直没有删除，那RocketMQ怎么知道应该投递过的消息就不再投递？——答案是客户端自身维护——客户端拉取完消息之后，在响应体中，broker会返回下一次应该拉取的位置，PushConsumer通过这一个位置，更新自己下一次的pull请求。这样就保证了正常情况下，消息只会被投递一次。</p>

<h2>什么时候清理物理消息文件？</h2>

<p>那消息文件到底删不删，什么时候删？</p>

<p>消息存储在CommitLog之后，的确是会被清理的，但是这个清理只会在以下任一条件成立才会批量删除消息文件（CommitLog）：</p>

<ol>
<li>消息文件过期（默认72小时），且到达清理时点（默认是凌晨4点），删除过期文件。</li>
<li>消息文件过期（默认72小时），且磁盘空间达到了水位线（默认75%），删除过期文件。</li>
<li>磁盘已经达到必须释放的上限（85%水位线）的时候，则开始批量清理文件（无论是否过期），直到空间充足。</li>
</ol>


<p>注：若磁盘空间达到危险水位线（默认90%），出于保护自身的目的，broker会拒绝写入服务。</p>

<h2>这样设计带来的好处</h2>

<p>消息的物理文件一直存在，消费逻辑只是听客户端的决定而搜索出对应消息进行，这样做，笔者认为，有以下几个好处：</p>

<ol>
<li><p>一个消息很可能需要被N个消费组（设计上很可能就是系统）消费，但消息只需要存储一份，消费进度单独记录即可。这给强大的消息堆积能力提供了很好的支持——一个消息无需复制N份，就可服务N个消费组。</p></li>
<li><p>由于消费从哪里消费的决定权一直都是客户端决定，所以只要消息还在，就可以消费到，这使得RocketMQ可以支持其他传统消息中间件不支持的回溯消费。即我可以通过设置消费进度回溯，就可以让我的消费组重新像放快照一样消费历史消息；或者我需要另一个系统也复制历史的数据，只需要另起一个消费组从头消费即可（前提是消息文件还存在）。</p></li>
<li><p>消息索引服务。只要消息还存在就能被搜索出来。所以可以依靠消息的索引搜索出消息的各种原信息，方便事后排查问题。</p></li>
</ol>


<p>注：在消息清理的时候，由于消息文件默认是1GB，所以在清理的时候其实是在删除一个大文件操作，这对于IO的压力是非常大的，这时候如果有消息写入，写入的耗时会明显变高。这个现象可以在凌晨4点（默认删时间时点）后的附近观察得到。</p>

<p>RocketMQ官方建议Linux下文件系统改为Ext4，对于文件删除操作相比Ext3有非常明显的提升。</p>

<h2>跳过历史消息的处理</h2>

<p>由于消息本身是没有过期的概念，只有文件才有过期的概念。那么对于很多业务场景——一个消息如果太老，是无需要被消费的，是不合适的。</p>

<p>这种需要跳过历史消息的场景，在RocketMQ要怎么实现呢？</p>

<p>对于一个全新的消费组，PushConsumer默认就是跳过以前的消息而从最尾开始消费的，解析请参看<a href="http://jaskey.github.io/blog/2017/01/25/rocketmq-consume-offset-management//" title="RocketMQ——消息ACK机制及消费进度管理">RocketMQ——消息ACK机制及消费进度管理</a>相关章节。</p>

<p>但对于已存在的消费组，RocketMQ没有内置的跳过历史消息的实现，但有以下手段可以解决：</p>

<ol>
<li><p>自身的消费代码按照日期过滤，太老的消息直接过滤。如：</p>

<pre><code>     @Override
     public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) {
         for(MessageExt msg: msgs){
             if(System.currentTimeMillis()-msg.getBornTimestamp()&gt;60*1000) {//一分钟之前的认为过期
                 continue;//过期消息跳过
             }

             //do consume here

         }
         return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
     }
</code></pre></li>
<li><p>自身的消费代码代码判断消息的offset和MAX_OFFSET相差很远，认为是积压了很多，直接return CONSUME_SUCCESS过滤。</p>

<pre><code>     @Override
     public ConsumeConcurrentlyStatus consumeMessage(//
         List&lt;MessageExt&gt; msgs, //
         ConsumeConcurrentlyContext context) {
         long offset = msgs.get(0).getQueueOffset();
         String maxOffset = msgs.get(0).getProperty(MessageConst.PROPERTY_MAX_OFFSET);
         long diff = Long. parseLong(maxOffset) - offset;
         if (diff &gt; 100000) { //消息堆积了10W情况的特殊处理
             return ConsumeConcurrentlyStatus. CONSUME_SUCCESS;
         }
         //do consume here
         return ConsumeConcurrentlyStatus. CONSUME_SUCCESS;
     }
</code></pre></li>
<li><p>消费者启动前，先调整该消费组的消费进度，再开始消费。可以人工使用控制台命令resetOffsetByTime把消费进度调整到后面，再启动消费。</p></li>
<li>原理同3，但使用代码来控制。代码中调用内部的运维接口，具体代码实例祥见<code>ResetOffsetByTimeCommand.java</code>.</li>
</ol>

]]></content>
  </entry>
  
</feed>
